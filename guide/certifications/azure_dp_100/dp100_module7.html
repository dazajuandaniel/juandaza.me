<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Azure DP-100 Module 7 | Juan Daza</title>
    <meta name="generator" content="VuePress 1.8.0">
    <link rel="apple-touch-icon" sizes="180x180" href="/favicons/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/favicons/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicons/favicon-16x16.png">
    <link rel="manifest" href="/favicons/site.webmanifest">
    <meta name="description" content="Personal Site - Data Science">
    <meta name="msapplication-TileColor" content="#3a0839">
    <meta name="theme-color" content="#ffffff">
    
    <link rel="preload" href="/assets/css/0.styles.155411b8.css" as="style"><link rel="preload" href="/assets/js/app.00f3e0b0.js" as="script"><link rel="preload" href="/assets/js/2.c8d9d072.js" as="script"><link rel="preload" href="/assets/js/45.287e648b.js" as="script"><link rel="prefetch" href="/assets/js/10.d1ce74f6.js"><link rel="prefetch" href="/assets/js/11.db0c7ded.js"><link rel="prefetch" href="/assets/js/12.0e8bfade.js"><link rel="prefetch" href="/assets/js/13.d2c3f67c.js"><link rel="prefetch" href="/assets/js/14.a5cb3f2e.js"><link rel="prefetch" href="/assets/js/15.ccfe6919.js"><link rel="prefetch" href="/assets/js/16.bb6c67c5.js"><link rel="prefetch" href="/assets/js/17.8686cb17.js"><link rel="prefetch" href="/assets/js/18.5ac61ac7.js"><link rel="prefetch" href="/assets/js/19.ec52a77c.js"><link rel="prefetch" href="/assets/js/20.1d7621d9.js"><link rel="prefetch" href="/assets/js/21.4d2f0a20.js"><link rel="prefetch" href="/assets/js/22.8b43a882.js"><link rel="prefetch" href="/assets/js/23.6f476c24.js"><link rel="prefetch" href="/assets/js/24.c946bec5.js"><link rel="prefetch" href="/assets/js/25.5389aff6.js"><link rel="prefetch" href="/assets/js/26.5af7ef7a.js"><link rel="prefetch" href="/assets/js/27.88109595.js"><link rel="prefetch" href="/assets/js/28.d8ac5fbb.js"><link rel="prefetch" href="/assets/js/29.a0b01f59.js"><link rel="prefetch" href="/assets/js/3.4039a9f7.js"><link rel="prefetch" href="/assets/js/30.58976856.js"><link rel="prefetch" href="/assets/js/31.d7c9b549.js"><link rel="prefetch" href="/assets/js/32.28bf3cab.js"><link rel="prefetch" href="/assets/js/33.364f88a5.js"><link rel="prefetch" href="/assets/js/34.728be2c6.js"><link rel="prefetch" href="/assets/js/35.7481a236.js"><link rel="prefetch" href="/assets/js/36.be835600.js"><link rel="prefetch" href="/assets/js/37.7fdab262.js"><link rel="prefetch" href="/assets/js/38.88e0b60c.js"><link rel="prefetch" href="/assets/js/39.44629cbc.js"><link rel="prefetch" href="/assets/js/4.5c0a74ad.js"><link rel="prefetch" href="/assets/js/40.229f6fa8.js"><link rel="prefetch" href="/assets/js/41.2e0cf19b.js"><link rel="prefetch" href="/assets/js/42.a403be76.js"><link rel="prefetch" href="/assets/js/43.931b7dce.js"><link rel="prefetch" href="/assets/js/44.8facc86f.js"><link rel="prefetch" href="/assets/js/46.1b0aa9a4.js"><link rel="prefetch" href="/assets/js/47.58ceb91b.js"><link rel="prefetch" href="/assets/js/48.4543261f.js"><link rel="prefetch" href="/assets/js/49.8cc5f4e3.js"><link rel="prefetch" href="/assets/js/5.cf6f72c1.js"><link rel="prefetch" href="/assets/js/50.1573841f.js"><link rel="prefetch" href="/assets/js/51.6d969b88.js"><link rel="prefetch" href="/assets/js/52.842e5214.js"><link rel="prefetch" href="/assets/js/53.fec48111.js"><link rel="prefetch" href="/assets/js/54.0b438294.js"><link rel="prefetch" href="/assets/js/55.054a8a1c.js"><link rel="prefetch" href="/assets/js/56.7988dab4.js"><link rel="prefetch" href="/assets/js/57.316f10c3.js"><link rel="prefetch" href="/assets/js/58.5d40f0f8.js"><link rel="prefetch" href="/assets/js/59.53cbce58.js"><link rel="prefetch" href="/assets/js/6.3c6a86b6.js"><link rel="prefetch" href="/assets/js/60.d68f7f00.js"><link rel="prefetch" href="/assets/js/61.de433280.js"><link rel="prefetch" href="/assets/js/62.aed76336.js"><link rel="prefetch" href="/assets/js/63.9173e78f.js"><link rel="prefetch" href="/assets/js/64.55fa77e4.js"><link rel="prefetch" href="/assets/js/65.248d9f16.js"><link rel="prefetch" href="/assets/js/66.4eb614ea.js"><link rel="prefetch" href="/assets/js/67.7d5a79cf.js"><link rel="prefetch" href="/assets/js/68.e5e2a825.js"><link rel="prefetch" href="/assets/js/69.e37eee26.js"><link rel="prefetch" href="/assets/js/7.e1ae24ba.js"><link rel="prefetch" href="/assets/js/70.7b01b8e9.js"><link rel="prefetch" href="/assets/js/71.23fd45d8.js"><link rel="prefetch" href="/assets/js/72.7c7b2f22.js"><link rel="prefetch" href="/assets/js/73.f2d0875a.js"><link rel="prefetch" href="/assets/js/74.d8257c99.js"><link rel="prefetch" href="/assets/js/75.b019001f.js"><link rel="prefetch" href="/assets/js/8.c0963d9f.js"><link rel="prefetch" href="/assets/js/9.18a35f9e.js">
    <link rel="stylesheet" href="/assets/css/0.styles.155411b8.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><img src="/photo.png" alt="Juan Daza" class="logo"> <span class="site-name can-hide">Juan Daza</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/home.html" class="nav-link">
  Home
</a></div><div class="nav-item"><a href="/cv.html" class="nav-link">
  CV
</a></div><div class="nav-item"><a href="https://www.linkedin.com/in/juandanieldaza" target="_blank" rel="noopener noreferrer" class="nav-link external">
  LinkedIn
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/home.html" class="nav-link">
  Home
</a></div><div class="nav-item"><a href="/cv.html" class="nav-link">
  CV
</a></div><div class="nav-item"><a href="https://www.linkedin.com/in/juandanieldaza" target="_blank" rel="noopener noreferrer" class="nav-link external">
  LinkedIn
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div> <!----></nav>  <ul class="sidebar-links"><li><a href="/" aria-current="page" class="sidebar-link">Home</a></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Help Snippets</span> <span class="arrow right"></span></p> <!----></section></li><li><a href="/guide/algos/" class="sidebar-link">Machine Learning</a></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Machine Learning</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Graphs</span> <span class="arrow right"></span></p> <!----></section></li><li><a href="/guide/mlops/" class="sidebar-link">ML OPS</a></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Ml Ops</span> <span class="arrow right"></span></p> <!----></section></li><li><a href="/guide/databricks/" class="sidebar-link">Databricks</a></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Databricks</span> <span class="arrow right"></span></p> <!----></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="azure-dp-100-module-7"><a href="#azure-dp-100-module-7" class="header-anchor">#</a> Azure DP-100 Module 7</h1> <h2 id="real-time-inferencing"><a href="#real-time-inferencing" class="header-anchor">#</a> Real-time Inferencing</h2> <p>AML allows you to deploy the inferencing service in a hosted platform such as AKS.</p> <h3 id="deploying-a-service"><a href="#deploying-a-service" class="header-anchor">#</a> Deploying a Service</h3> <p>AML uses <code>containers</code> as a deployment mechanism, packaging the model and code to be able to be deployed into a container in whatever target (local, ACI, AKS, Azure Function, etc).</p> <p><strong>General Steps to deploy</strong></p> <ol><li><p>Register a trained model in the workspace</p></li> <li><p>Define an Inference Configuration</p> <ul><li>The model consists of a <em>script to load the model</em> and <em>an enviroment the script will run</em></li></ul></li> <li><p>Create an entry Script</p> <ul><li><p>Script must have <code>init()</code> and <code>run(raw_data)</code> function</p> <ul><li>init(): Called when the services is initialised (e.g. load the model)</li> <li>run(raw_data): Called when new data is submitted (e.g. generating predictions)</li></ul> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> json
<span class="token keyword">import</span> joblib
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> azureml<span class="token punctuation">.</span>core<span class="token punctuation">.</span>model <span class="token keyword">import</span> Model

<span class="token comment"># Called when the service is loaded</span>
<span class="token keyword">def</span> <span class="token function">init</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">global</span> model
    <span class="token comment"># Get the path to the registered model file and load it</span>
    model_path <span class="token operator">=</span> Model<span class="token punctuation">.</span>get_model_path<span class="token punctuation">(</span><span class="token string">'classification_model'</span><span class="token punctuation">)</span>
    model <span class="token operator">=</span> joblib<span class="token punctuation">.</span>load<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span>

<span class="token comment"># Called when a request is received</span>
<span class="token keyword">def</span> <span class="token function">run</span><span class="token punctuation">(</span>raw_data<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># Get the input data as a numpy array</span>
    data <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>raw_data<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token string">'data'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token comment"># Get a prediction from the model</span>
    predictions <span class="token operator">=</span> model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
    <span class="token comment"># Return the predictions as any JSON serializable format</span>
    <span class="token keyword">return</span> predictions<span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div></li></ul></li> <li><p>Create the environment:</p> <ul><li>You can configure using Conda configuration file using the <code>CondaDependencies</code> class.</li></ul> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">from</span> azureml<span class="token punctuation">.</span>core<span class="token punctuation">.</span>conda_dependencies <span class="token keyword">import</span> CondaDependencies

<span class="token comment"># Add the dependencies for your model</span>
myenv <span class="token operator">=</span> CondaDependencies<span class="token punctuation">(</span><span class="token punctuation">)</span>
myenv<span class="token punctuation">.</span>add_conda_package<span class="token punctuation">(</span><span class="token string">&quot;scikit-learn&quot;</span><span class="token punctuation">)</span>

<span class="token comment"># Save the environment config as a .yml file</span>
env_file <span class="token operator">=</span> <span class="token string">'service_files/env.yml'</span>
<span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>env_file<span class="token punctuation">,</span><span class="token string">&quot;w&quot;</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
    f<span class="token punctuation">.</span>write<span class="token punctuation">(</span>myenv<span class="token punctuation">.</span>serialize_to_string<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;Saved dependency info in&quot;</span><span class="token punctuation">,</span> env_file<span class="token punctuation">)</span>
</code></pre></div></li> <li><p>Combine Script + Environment</p> <ul><li>Combine it using the <code>InferenceConfig</code></li></ul> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">from</span> azureml<span class="token punctuation">.</span>core<span class="token punctuation">.</span>model <span class="token keyword">import</span> InferenceConfig

classifier_inference_config <span class="token operator">=</span> InferenceConfig<span class="token punctuation">(</span>runtime<span class="token operator">=</span> <span class="token string">&quot;python&quot;</span><span class="token punctuation">,</span>
                                            source_directory <span class="token operator">=</span> <span class="token string">'service_files'</span><span class="token punctuation">,</span>
                                            entry_script<span class="token operator">=</span><span class="token string">&quot;score.py&quot;</span><span class="token punctuation">,</span>
                                            conda_file<span class="token operator">=</span><span class="token string">&quot;env.yml&quot;</span><span class="token punctuation">)</span>
</code></pre></div></li> <li><p>Define a deployment Configuration</p> <ul><li>Configure the compute to which the service will be deployed.</li></ul> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">from</span> azureml<span class="token punctuation">.</span>core<span class="token punctuation">.</span>compute <span class="token keyword">import</span> ComputeTarget<span class="token punctuation">,</span> AksCompute
<span class="token keyword">from</span> azureml<span class="token punctuation">.</span>core<span class="token punctuation">.</span>webservice <span class="token keyword">import</span> AksWebservice


cluster_name <span class="token operator">=</span> <span class="token string">'aks-cluster'</span>
compute_config <span class="token operator">=</span> AksCompute<span class="token punctuation">.</span>provisioning_configuration<span class="token punctuation">(</span>location<span class="token operator">=</span><span class="token string">'eastus'</span><span class="token punctuation">)</span>
production_cluster <span class="token operator">=</span> ComputeTarget<span class="token punctuation">.</span>create<span class="token punctuation">(</span>ws<span class="token punctuation">,</span> cluster_name<span class="token punctuation">,</span> compute_config<span class="token punctuation">)</span>
production_cluster<span class="token punctuation">.</span>wait_for_completion<span class="token punctuation">(</span>show_output<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
classifier_deploy_config <span class="token operator">=</span> AksWebservice<span class="token punctuation">.</span>deploy_configuration<span class="token punctuation">(</span>cpu_cores <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span>
                                                            memory_gb <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span>
</code></pre></div></li> <li><p>Deploy the model</p> <ul><li>Call <code>deploy</code> method of the <code>Model</code> class.</li></ul></li></ol> <h4 id="consuming-an-inferencing-service"><a href="#consuming-an-inferencing-service" class="header-anchor">#</a> Consuming an Inferencing Service</h4> <p>To consume you can use the endpoint to make calls. For authentication you need the either the <code>key</code> or <code>token</code> (JWT).</p> <p><strong>Notes:</strong></p> <div class="language- extra-class"><pre><code>* Authentication is disabled by default for ACI services
* Autehntication is set to key-based for AKS
* For token-based authentication, your client application needs to use service-principal authentication to verify its identity through Azure Active Directory (Azure AD) and call the get_token method of the service to retrieve a time-limited token.
</code></pre></div><h4 id="troubleshooting"><a href="#troubleshooting" class="header-anchor">#</a> Troubleshooting</h4> <ol><li>Check the state by using the <code>state</code> method (use a service specific method such as <code>AksWebservice</code> instead of <code>WebService</code>).<div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">from</span> azureml<span class="token punctuation">.</span>core<span class="token punctuation">.</span>webservice <span class="token keyword">import</span> AksWebservice

<span class="token comment"># Get the deployed service</span>
service <span class="token operator">=</span> AciWebservice<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">'classifier-service'</span><span class="token punctuation">,</span> workspace<span class="token operator">=</span>ws<span class="token punctuation">)</span>

<span class="token comment"># Check its state</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>service<span class="token punctuation">.</span>state<span class="token punctuation">)</span>
</code></pre></div></li> <li>Review Service Logs<div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">print</span><span class="token punctuation">(</span>service<span class="token punctuation">.</span>get_logs<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div></li> <li>Deploy to local container for easy diagnosis</li></ol> <h3 id="batch-inferencing"><a href="#batch-inferencing" class="header-anchor">#</a> Batch Inferencing</h3> <p>Apply predictive models to batch operations <code>asynchronously</code> and write results to a DB/file.</p> <h4 id="create-batch-pipeline"><a href="#create-batch-pipeline" class="header-anchor">#</a> Create Batch Pipeline</h4> <p><strong>General Steps to deploy</strong></p> <ol><li><p>Register the model (similar to Real Time inferencing)</p></li> <li><p>Create a scoring script:</p> <ul><li><p>Script must have <code>init()</code> and <code>run(mini_batch)</code> function</p> <ul><li>init(): Called when the pipeline is initialised (e.g. load the model)</li> <li>run(raw_data): Called for each batch (e.g. generating predictions)</li></ul> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> json
<span class="token keyword">import</span> joblib
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> azureml<span class="token punctuation">.</span>core<span class="token punctuation">.</span>model <span class="token keyword">import</span> Model

<span class="token comment"># Called when the service is loaded</span>
<span class="token keyword">def</span> <span class="token function">init</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">global</span> model
    <span class="token comment"># Get the path to the registered model file and load it</span>
    model_path <span class="token operator">=</span> Model<span class="token punctuation">.</span>get_model_path<span class="token punctuation">(</span><span class="token string">'classification_model'</span><span class="token punctuation">)</span>
    model <span class="token operator">=</span> joblib<span class="token punctuation">.</span>load<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span>

<span class="token comment"># Called when a request is received</span>
<span class="token keyword">def</span> <span class="token function">run</span><span class="token punctuation">(</span>mini_batch<span class="token punctuation">)</span><span class="token punctuation">:</span>
   <span class="token comment"># process each file in the batch</span>
    <span class="token keyword">for</span> f <span class="token keyword">in</span> mini_batch<span class="token punctuation">:</span>
        <span class="token comment"># Read comma-delimited data into an array</span>
        data <span class="token operator">=</span> np<span class="token punctuation">.</span>genfromtxt<span class="token punctuation">(</span>f<span class="token punctuation">,</span> delimiter<span class="token operator">=</span><span class="token string">','</span><span class="token punctuation">)</span>
        <span class="token comment"># Reshape into a 2-dimensional array for model input</span>
        prediction <span class="token operator">=</span> model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>data<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token comment"># Append prediction to results</span>
        resultList<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string">&quot;{}: {}&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>basename<span class="token punctuation">(</span>f<span class="token punctuation">)</span><span class="token punctuation">,</span> prediction<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> resultList
</code></pre></div></li></ul></li> <li><p>Create a Pipeline with a <code>ParallelRunStep</code></p> <ul><li>AML provides a step to perform parallel batch inferencing (<code>ParallelRunStep</code>). Output can be written to a <code>PipelineData</code> reference. Also, you can set the <code>output_action = append_row</code> setting to ensure that all instances of the step that are run in parallel, collate their results to a single file</li></ul> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">from</span> azureml<span class="token punctuation">.</span>pipeline<span class="token punctuation">.</span>steps <span class="token keyword">import</span> ParallelRunConfig<span class="token punctuation">,</span> ParallelRunStep
<span class="token keyword">from</span> azureml<span class="token punctuation">.</span>pipeline<span class="token punctuation">.</span>core <span class="token keyword">import</span> PipelineData
<span class="token keyword">from</span> azureml<span class="token punctuation">.</span>pipeline<span class="token punctuation">.</span>core <span class="token keyword">import</span> Pipeline

<span class="token comment"># Get the batch dataset for input</span>
batch_data_set <span class="token operator">=</span> ws<span class="token punctuation">.</span>datasets<span class="token punctuation">[</span><span class="token string">'batch-data'</span><span class="token punctuation">]</span>

<span class="token comment"># Set the output location</span>
default_ds <span class="token operator">=</span> ws<span class="token punctuation">.</span>get_default_datastore<span class="token punctuation">(</span><span class="token punctuation">)</span>
output_dir <span class="token operator">=</span> PipelineData<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">'inferences'</span><span class="token punctuation">,</span>
                        datastore<span class="token operator">=</span>default_ds<span class="token punctuation">,</span>
                        output_path_on_compute<span class="token operator">=</span><span class="token string">'results'</span><span class="token punctuation">)</span>

<span class="token comment"># Define the parallel run step step configuration</span>
parallel_run_config <span class="token operator">=</span> ParallelRunConfig<span class="token punctuation">(</span>
    source_directory<span class="token operator">=</span><span class="token string">'batch_scripts'</span><span class="token punctuation">,</span>
    entry_script<span class="token operator">=</span><span class="token string">&quot;batch_scoring_script.py&quot;</span><span class="token punctuation">,</span>
    mini_batch_size<span class="token operator">=</span><span class="token string">&quot;5&quot;</span><span class="token punctuation">,</span>
    error_threshold<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>
    output_action<span class="token operator">=</span><span class="token string">&quot;append_row&quot;</span><span class="token punctuation">,</span>
    environment<span class="token operator">=</span>batch_env<span class="token punctuation">,</span>
    compute_target<span class="token operator">=</span>aml_cluster<span class="token punctuation">,</span>
    node_count<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span>

<span class="token comment"># Create the parallel run step</span>
parallelrun_step <span class="token operator">=</span> ParallelRunStep<span class="token punctuation">(</span>
    name<span class="token operator">=</span><span class="token string">'batch-score'</span><span class="token punctuation">,</span>
    parallel_run_config<span class="token operator">=</span>parallel_run_config<span class="token punctuation">,</span>
    inputs<span class="token operator">=</span><span class="token punctuation">[</span>batch_data_set<span class="token punctuation">.</span>as_named_input<span class="token punctuation">(</span><span class="token string">'batch_data'</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    output<span class="token operator">=</span>output_dir<span class="token punctuation">,</span>
    arguments<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    allow_reuse<span class="token operator">=</span><span class="token boolean">True</span>
<span class="token punctuation">)</span>
<span class="token comment"># Create the pipeline</span>
pipeline <span class="token operator">=</span> Pipeline<span class="token punctuation">(</span>workspace<span class="token operator">=</span>ws<span class="token punctuation">,</span> steps<span class="token operator">=</span><span class="token punctuation">[</span>parallelrun_step<span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre></div></li> <li><p>Run the pipeline and retrieve Step Output</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">from</span> azureml<span class="token punctuation">.</span>core <span class="token keyword">import</span> Experiment

<span class="token comment"># Run the pipeline as an experiment</span>
pipeline_run <span class="token operator">=</span> Experiment<span class="token punctuation">(</span>ws<span class="token punctuation">,</span> <span class="token string">'batch_prediction_pipeline'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>submit<span class="token punctuation">(</span>pipeline<span class="token punctuation">)</span>
pipeline_run<span class="token punctuation">.</span>wait_for_completion<span class="token punctuation">(</span>show_output<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment"># Get the outputs from the first (and only) step</span>
prediction_run <span class="token operator">=</span> <span class="token builtin">next</span><span class="token punctuation">(</span>pipeline_run<span class="token punctuation">.</span>get_children<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
prediction_output <span class="token operator">=</span> prediction_run<span class="token punctuation">.</span>get_output_data<span class="token punctuation">(</span><span class="token string">'inferences'</span><span class="token punctuation">)</span>
prediction_output<span class="token punctuation">.</span>download<span class="token punctuation">(</span>local_path<span class="token operator">=</span><span class="token string">'results'</span><span class="token punctuation">)</span>

<span class="token comment"># Find the parallel_run_step.txt file</span>
<span class="token keyword">for</span> root<span class="token punctuation">,</span> dirs<span class="token punctuation">,</span> files <span class="token keyword">in</span> os<span class="token punctuation">.</span>walk<span class="token punctuation">(</span><span class="token string">'results'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> <span class="token builtin">file</span> <span class="token keyword">in</span> files<span class="token punctuation">:</span>
        <span class="token keyword">if</span> <span class="token builtin">file</span><span class="token punctuation">.</span>endswith<span class="token punctuation">(</span><span class="token string">'parallel_run_step.txt'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            result_file <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>root<span class="token punctuation">,</span><span class="token builtin">file</span><span class="token punctuation">)</span>

<span class="token comment"># Load and display the results</span>
df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>result_file<span class="token punctuation">,</span> delimiter<span class="token operator">=</span><span class="token string">&quot;:&quot;</span><span class="token punctuation">,</span> header<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span>
df<span class="token punctuation">.</span>columns <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">&quot;File&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;Prediction&quot;</span><span class="token punctuation">]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>df<span class="token punctuation">)</span>
</code></pre></div></li></ol> <h4 id="publishing-batch-service"><a href="#publishing-batch-service" class="header-anchor">#</a> Publishing Batch Service</h4> <p>Same as Real Time Publishing.</p> <ol><li>Publish as a Rest service</li> <li>Use the service to intiate the pipeline on demand</li> <li>You can Schedule the pipeline as well using the <code>ScheduleRecurrence</code> and <code>Schedule</code> object.</li></ol></div> <footer class="page-edit"><!----> <!----></footer> <!----> </main></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.00f3e0b0.js" defer></script><script src="/assets/js/2.c8d9d072.js" defer></script><script src="/assets/js/45.287e648b.js" defer></script>
  </body>
</html>
