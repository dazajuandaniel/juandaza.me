<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Azure DP-100 Day 2 | Juan Daza</title>
    <meta name="generator" content="VuePress 1.8.0">
    <link rel="apple-touch-icon" sizes="180x180" href="/favicons/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/favicons/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicons/favicon-16x16.png">
    <link rel="manifest" href="/favicons/site.webmanifest">
    <meta name="description" content="Personal Site - Data Science">
    <meta name="msapplication-TileColor" content="#3a0839">
    <meta name="theme-color" content="#ffffff">
    
    <link rel="preload" href="/assets/css/0.styles.155411b8.css" as="style"><link rel="preload" href="/assets/js/app.4a47de2e.js" as="script"><link rel="preload" href="/assets/js/2.c8d9d072.js" as="script"><link rel="preload" href="/assets/js/48.2d3aeb95.js" as="script"><link rel="prefetch" href="/assets/js/10.d1ce74f6.js"><link rel="prefetch" href="/assets/js/11.db0c7ded.js"><link rel="prefetch" href="/assets/js/12.0e8bfade.js"><link rel="prefetch" href="/assets/js/13.d2c3f67c.js"><link rel="prefetch" href="/assets/js/14.a5cb3f2e.js"><link rel="prefetch" href="/assets/js/15.ccfe6919.js"><link rel="prefetch" href="/assets/js/16.bb6c67c5.js"><link rel="prefetch" href="/assets/js/17.8686cb17.js"><link rel="prefetch" href="/assets/js/18.5ac61ac7.js"><link rel="prefetch" href="/assets/js/19.ec52a77c.js"><link rel="prefetch" href="/assets/js/20.a9bea395.js"><link rel="prefetch" href="/assets/js/21.4d2f0a20.js"><link rel="prefetch" href="/assets/js/22.8b43a882.js"><link rel="prefetch" href="/assets/js/23.6f476c24.js"><link rel="prefetch" href="/assets/js/24.c946bec5.js"><link rel="prefetch" href="/assets/js/25.5389aff6.js"><link rel="prefetch" href="/assets/js/26.62000833.js"><link rel="prefetch" href="/assets/js/27.594aaf4c.js"><link rel="prefetch" href="/assets/js/28.f8bc56de.js"><link rel="prefetch" href="/assets/js/29.db422c26.js"><link rel="prefetch" href="/assets/js/3.4039a9f7.js"><link rel="prefetch" href="/assets/js/30.f64ceb79.js"><link rel="prefetch" href="/assets/js/31.dcdced45.js"><link rel="prefetch" href="/assets/js/32.d326cd4a.js"><link rel="prefetch" href="/assets/js/33.fac86654.js"><link rel="prefetch" href="/assets/js/34.4e1824e0.js"><link rel="prefetch" href="/assets/js/35.2c7bccc6.js"><link rel="prefetch" href="/assets/js/36.48a9e052.js"><link rel="prefetch" href="/assets/js/37.93f2dc5c.js"><link rel="prefetch" href="/assets/js/38.ee1c2de6.js"><link rel="prefetch" href="/assets/js/39.ee5a361c.js"><link rel="prefetch" href="/assets/js/4.8a3ee82c.js"><link rel="prefetch" href="/assets/js/40.af5d0fbf.js"><link rel="prefetch" href="/assets/js/41.419de009.js"><link rel="prefetch" href="/assets/js/42.9aa1a60d.js"><link rel="prefetch" href="/assets/js/43.c35441db.js"><link rel="prefetch" href="/assets/js/44.afb3535e.js"><link rel="prefetch" href="/assets/js/45.e8300247.js"><link rel="prefetch" href="/assets/js/46.5bc60679.js"><link rel="prefetch" href="/assets/js/47.3048d565.js"><link rel="prefetch" href="/assets/js/49.bd82cfb7.js"><link rel="prefetch" href="/assets/js/5.cf6f72c1.js"><link rel="prefetch" href="/assets/js/50.9383a5f8.js"><link rel="prefetch" href="/assets/js/51.eb6689c9.js"><link rel="prefetch" href="/assets/js/52.cc29ff05.js"><link rel="prefetch" href="/assets/js/53.3542ae16.js"><link rel="prefetch" href="/assets/js/54.f7cdc2c4.js"><link rel="prefetch" href="/assets/js/55.d0548403.js"><link rel="prefetch" href="/assets/js/56.44962748.js"><link rel="prefetch" href="/assets/js/57.518e7fd7.js"><link rel="prefetch" href="/assets/js/58.2a14ed2e.js"><link rel="prefetch" href="/assets/js/59.61e9ba38.js"><link rel="prefetch" href="/assets/js/6.3c6a86b6.js"><link rel="prefetch" href="/assets/js/60.7f65ff79.js"><link rel="prefetch" href="/assets/js/61.1b7988ad.js"><link rel="prefetch" href="/assets/js/62.d8d513ba.js"><link rel="prefetch" href="/assets/js/63.6bbdeb34.js"><link rel="prefetch" href="/assets/js/7.e1ae24ba.js"><link rel="prefetch" href="/assets/js/8.c0963d9f.js"><link rel="prefetch" href="/assets/js/9.18a35f9e.js">
    <link rel="stylesheet" href="/assets/css/0.styles.155411b8.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><img src="/photo.png" alt="Juan Daza" class="logo"> <span class="site-name can-hide">Juan Daza</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/home.html" class="nav-link">
  Home
</a></div><div class="nav-item"><a href="/cv.html" class="nav-link">
  CV
</a></div><div class="nav-item"><a href="https://www.linkedin.com/in/juandanieldaza" target="_blank" rel="noopener noreferrer" class="nav-link external">
  LinkedIn
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/home.html" class="nav-link">
  Home
</a></div><div class="nav-item"><a href="/cv.html" class="nav-link">
  CV
</a></div><div class="nav-item"><a href="https://www.linkedin.com/in/juandanieldaza" target="_blank" rel="noopener noreferrer" class="nav-link external">
  LinkedIn
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div> <!----></nav>  <ul class="sidebar-links"><li><a href="/" aria-current="page" class="sidebar-link">Home</a></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Help Snippets</span> <span class="arrow right"></span></p> <!----></section></li><li><a href="/guide/algos/" class="sidebar-link">Machine Learning</a></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Machine Learning</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Graphs</span> <span class="arrow right"></span></p> <!----></section></li><li><a href="/guide/mlops/" class="sidebar-link">ML OPS</a></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Ml Ops</span> <span class="arrow right"></span></p> <!----></section></li><li><a href="/guide/certifications/" aria-current="page" class="sidebar-link">Cloud Certification</a></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>AWS SA</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading open"><span>Azure ML DP-100</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/guide/certifications/azure_dp_100/dp100_exam_review.html" class="sidebar-link">Azure DP-100 Exam Review Topics</a></li><li><a href="/guide/certifications/azure_dp_100/dp100_aml_summary.html" class="sidebar-link">Azure DP-100 Summary</a></li><li><a href="/guide/certifications/azure_dp_100/dp100_pt1.html" class="sidebar-link">Azure DP-100 Day 1</a></li><li><a href="/guide/certifications/azure_dp_100/dp100_pt2.html" aria-current="page" class="active sidebar-link">Azure DP-100 Day 2</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/guide/certifications/azure_dp_100/dp100_pt2.html#working-with-data" class="sidebar-link">Working with Data</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/guide/certifications/azure_dp_100/dp100_pt2.html#datastores" class="sidebar-link">Datastores</a></li><li class="sidebar-sub-header"><a href="/guide/certifications/azure_dp_100/dp100_pt2.html#data-in-workspaces" class="sidebar-link">Data in Workspaces</a></li><li class="sidebar-sub-header"><a href="/guide/certifications/azure_dp_100/dp100_pt2.html#datasets" class="sidebar-link">Datasets</a></li></ul></li><li class="sidebar-sub-header"><a href="/guide/certifications/azure_dp_100/dp100_pt2.html#compute-contexts" class="sidebar-link">Compute Contexts</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/guide/certifications/azure_dp_100/dp100_pt2.html#environments" class="sidebar-link">Environments</a></li><li class="sidebar-sub-header"><a href="/guide/certifications/azure_dp_100/dp100_pt2.html#compute-targets" class="sidebar-link">Compute Targets</a></li></ul></li><li class="sidebar-sub-header"><a href="/guide/certifications/azure_dp_100/dp100_pt2.html#pipelines" class="sidebar-link">Pipelines</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/guide/certifications/azure_dp_100/dp100_pt2.html#pipeline-steps" class="sidebar-link">Pipeline Steps</a></li></ul></li></ul></li><li><a href="/guide/certifications/azure_dp_100/dp100_pt3.html" class="sidebar-link">Azure DP-100 Day 3</a></li><li><a href="/guide/certifications/azure_dp_100/dp100_module1.html" class="sidebar-link">Azure DP-100 Module 1</a></li><li><a href="/guide/certifications/azure_dp_100/dp100_module2.html" class="sidebar-link">Azure DP-100 Module 2</a></li><li><a href="/guide/certifications/azure_dp_100/dp100_module3.html" class="sidebar-link">Azure DP-100 Module 3</a></li><li><a href="/guide/certifications/azure_dp_100/dp100_module4.html" class="sidebar-link">Azure DP-100 Module 4</a></li><li><a href="/guide/certifications/azure_dp_100/dp100_module5.html" class="sidebar-link">Azure DP-100 Module 5</a></li><li><a href="/guide/certifications/azure_dp_100/dp100_module6.html" class="sidebar-link">Azure DP-100 Module 6</a></li><li><a href="/guide/certifications/azure_dp_100/dp100_module7.html" class="sidebar-link">Azure DP-100 Module 7</a></li><li><a href="/guide/certifications/azure_dp_100/dp100_module8.html" class="sidebar-link">Azure DP-100 Module 8</a></li><li><a href="/guide/certifications/azure_dp_100/dp100_module9.html" class="sidebar-link">Azure DP-100 Module 9</a></li><li><a href="/guide/certifications/azure_dp_100/dp100_module10.html" class="sidebar-link">Azure DP-100 Module 10</a></li></ul></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="azure-dp-100-day-2"><a href="#azure-dp-100-day-2" class="header-anchor">#</a> Azure DP-100 Day 2</h1> <h2 id="working-with-data"><a href="#working-with-data" class="header-anchor">#</a> Working with Data</h2> <p>In Azure Machine Learning, <code>datastores</code> are abstractions for cloud data sources</p> <h3 id="datastores"><a href="#datastores" class="header-anchor">#</a> Datastores</h3> <ul><li>Abstractions for cloud data sources
<ul><li>Azure Storage</li> <li>Data Lake/SQL DB/Databricks</li></ul></li> <li>Enable data access from workspace
<ul><li>Upload/Download</li> <li>Remote Mount</li></ul></li></ul> <p>You can access datastores directly in code by using the Azure Machine Learning SDK, and use it to upload or download data. You can also mount a datastore in an experiment in order to read or write data.</p> <h3 id="data-in-workspaces"><a href="#data-in-workspaces" class="header-anchor">#</a> Data in Workspaces</h3> <p>Every workspace has two built-in datastores (an Azure Storage blob container, and an Azure Storage file container) that are used as system storage by Azure Machine Learning. However, more custom can be added easily with SDK. Similarly, the SDK allows for management of the datastores.</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">from</span> azureml<span class="token punctuation">.</span>core <span class="token keyword">import</span> Workspace<span class="token punctuation">,</span> Datastore

ws <span class="token operator">=</span> Workspace<span class="token punctuation">.</span>from_config<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># Register a new datastore</span>
blob_ds <span class="token operator">=</span> Datastore<span class="token punctuation">.</span>register_azure_blob_container<span class="token punctuation">(</span>workspace<span class="token operator">=</span>ws<span class="token punctuation">,</span>
                                                  datastore_name<span class="token operator">=</span><span class="token string">'blob_data'</span><span class="token punctuation">,</span>
                                                  container_name<span class="token operator">=</span><span class="token string">'data_container'</span><span class="token punctuation">,</span>
                                                  account_name<span class="token operator">=</span><span class="token string">'az_store_acct'</span><span class="token punctuation">,</span>
                                                  account_key<span class="token operator">=</span><span class="token string">'123456abcde789…'</span><span class="token punctuation">)</span>
</code></pre></div><p>Azure blob and file datastores are the most commonly used. You can use the Azure Machine Learning SDK to work directly with these datastores, and to pass  <code>data references</code>  to scripts that need to access data.</p> <p>To work directly with a datastore, the class <code>datastore</code> is required</p> <div class="language-python extra-class"><pre class="language-python"><code>blob_ds<span class="token punctuation">.</span>upload<span class="token punctuation">(</span>src_dir<span class="token operator">=</span><span class="token string">'/files'</span><span class="token punctuation">,</span>
               target_path<span class="token operator">=</span><span class="token string">'/data/files'</span><span class="token punctuation">,</span>
               overwrite<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> show_progress<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

blob_ds<span class="token punctuation">.</span>download<span class="token punctuation">(</span>target_path<span class="token operator">=</span><span class="token string">'downloads'</span><span class="token punctuation">,</span>
                 prefix<span class="token operator">=</span><span class="token string">'/data'</span><span class="token punctuation">,</span>
                 show_progress<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
</code></pre></div><h3 id="datasets"><a href="#datasets" class="header-anchor">#</a> Datasets</h3> <p><code>Datasets</code> are versioned packaged data objects that can be easily consumed in experiments and pipelines. Datasets are the recommended way to work with data, and are the primary mechanism for advanced Azure Machine Learning capabilities like data labeling and data drift monitoring.</p> <p>You can create a dataset and work with it immediately, and you can then  <code>register</code>  the dataset in the workspace to make it available for use in experiments and data processing pipelines later.</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">from</span> azureml<span class="token punctuation">.</span>core <span class="token keyword">import</span> Dataset

blob_ds <span class="token operator">=</span> ws<span class="token punctuation">.</span>get_default_datastore<span class="token punctuation">(</span><span class="token punctuation">)</span>
csv_paths <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">(</span>blob_ds<span class="token punctuation">,</span> <span class="token string">'data/files/current_data.csv'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
             <span class="token punctuation">(</span>blob_ds<span class="token punctuation">,</span> <span class="token string">'data/files/archive/*.csv'</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
tab_ds <span class="token operator">=</span> Dataset<span class="token punctuation">.</span>Tabular<span class="token punctuation">.</span>from_delimited_files<span class="token punctuation">(</span>path<span class="token operator">=</span>csv_paths<span class="token punctuation">)</span>
tab_ds <span class="token operator">=</span> tab_ds<span class="token punctuation">.</span>register<span class="token punctuation">(</span>workspace<span class="token operator">=</span>ws<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'csv_table'</span><span class="token punctuation">)</span>
</code></pre></div><p>Datasets can be  <code>versioned</code>, enabling you to track historical versions of datasets that were used in experiments, and reproduce those experiments with data in the same state.</p> <h2 id="compute-contexts"><a href="#compute-contexts" class="header-anchor">#</a> Compute Contexts</h2> <h3 id="environments"><a href="#environments" class="header-anchor">#</a> Environments</h3> <p>Python code runs in the context of a <code>virtual environment</code> that defines the version of the Python runtime to be used as well as the installed packages available to the code. In most Python installations, packages are installed and managed in environments using <strong>Conda</strong> or <strong>pip</strong>.</p> <p>Environments are encapsulated by the <strong>Environment</strong> class; which you can use to create environments and specify runtime configuration for an experiment. In general, Azure Machine Learning handles environment creation and package installation for you. You can specify the Conda or pip packages you need, and have Azure Machine Learning create an environment for the experiment. You can manage your own environments and register them as well.</p> <h4 id="creating-environments-registering-environments"><a href="#creating-environments-registering-environments" class="header-anchor">#</a> Creating Environments &amp; Registering Environments</h4> <ol><li>From Spec file</li></ol> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">from</span> azureml<span class="token punctuation">.</span>core <span class="token keyword">import</span> Environment

env <span class="token operator">=</span> Environment<span class="token punctuation">.</span>from_conda_specification<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">'training_environment'</span><span class="token punctuation">,</span>
                                           file_path<span class="token operator">=</span><span class="token string">'./conda.yml'</span><span class="token punctuation">)</span>
</code></pre></div><ol start="2"><li>From Existing Conda Environment</li></ol> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">from</span> azureml<span class="token punctuation">.</span>core <span class="token keyword">import</span> Environment

env <span class="token operator">=</span> Environment<span class="token punctuation">.</span>from_existing_conda_environment<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">'training_environment'</span><span class="token punctuation">,</span>
                                                  conda_environment_name<span class="token operator">=</span><span class="token string">'py_env'</span><span class="token punctuation">)</span>
</code></pre></div><ol start="3"><li>By Specifying Packages</li></ol> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">from</span> azureml<span class="token punctuation">.</span>core <span class="token keyword">import</span> Environment
<span class="token keyword">from</span> azureml<span class="token punctuation">.</span>core<span class="token punctuation">.</span>conda_dependencies <span class="token keyword">import</span> CondaDependencies

env <span class="token operator">=</span> Environment<span class="token punctuation">(</span><span class="token string">'training_environment'</span><span class="token punctuation">)</span>
deps <span class="token operator">=</span> CondaDependencies<span class="token punctuation">.</span>create<span class="token punctuation">(</span>conda_packages<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'scikit-learn'</span><span class="token punctuation">,</span><span class="token string">'pandas'</span><span class="token punctuation">,</span><span class="token string">'numpy'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                                pip_packages<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'azureml-defaults'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
env<span class="token punctuation">.</span>python<span class="token punctuation">.</span>conda_dependencies <span class="token operator">=</span> deps
</code></pre></div><p>After you've created an environment, you can register it in your workspace and reuse it for future experiments that have the same Python dependencies.</p> <div class="language-python extra-class"><pre class="language-python"><code>env<span class="token punctuation">.</span>register<span class="token punctuation">(</span>workspace<span class="token operator">=</span>ws<span class="token punctuation">)</span>
</code></pre></div><p>To retrieve and use an environment</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">from</span> azureml<span class="token punctuation">.</span>core <span class="token keyword">import</span> Environment
<span class="token keyword">from</span> azureml<span class="token punctuation">.</span>train<span class="token punctuation">.</span>estimator <span class="token keyword">import</span> Estimator

training_env <span class="token operator">=</span> Environment<span class="token punctuation">.</span>get<span class="token punctuation">(</span>workspace<span class="token operator">=</span>ws<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'training_environment'</span><span class="token punctuation">)</span>
estimator <span class="token operator">=</span> Estimator<span class="token punctuation">(</span>source_directory<span class="token operator">=</span><span class="token string">'experiment_folder'</span>
                      entry_script<span class="token operator">=</span><span class="token string">'training_script.py'</span><span class="token punctuation">,</span>
                      compute_target<span class="token operator">=</span><span class="token string">'local'</span><span class="token punctuation">,</span>
                      environment_definition<span class="token operator">=</span>training_env<span class="token punctuation">)</span>
</code></pre></div><p>Curated environments are registered in all Azure Machine Learning workspaces with a name that begins  <strong>AzureML-</strong>.</p> <p><strong>Note</strong>: You can't register your own environments with an “AzureML-” prefix.</p> <h3 id="compute-targets"><a href="#compute-targets" class="header-anchor">#</a> Compute Targets</h3> <p><code>Compute Targets</code> are physical or virtual computers on which experiments are run.</p> <div class="language- extra-class"><pre><code>* Local compute: This runs the experiment on the same compute target as the code used to initiate the experiment
* Compute Clusters: For experiment with high scalability requirements, you can use Azure Machine Learning compute clusters
* Inference Clusters: To deploy trained models as production services, you can use Azure Machine Learning inference clusters
* Attached Compute: If you already use an Azure-based compute environment for data science, such as a virtual machine or an Azure Databricks cluster, you can attach it to your Azure Machine Learning workspace and use it as a compute target for certain types of workload.
</code></pre></div><h4 id="using-compute-targets"><a href="#using-compute-targets" class="header-anchor">#</a> Using Compute Targets</h4> <p>To use a particular compute target, you can specify it in the appropriate parameter for an experiment run configuration or estimator</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">from</span> azureml<span class="token punctuation">.</span>core <span class="token keyword">import</span> Environment
<span class="token keyword">from</span> azureml<span class="token punctuation">.</span>train<span class="token punctuation">.</span>estimator <span class="token keyword">import</span> Estimator

compute_name <span class="token operator">=</span> <span class="token string">'aml-cluster'</span>

training_env <span class="token operator">=</span> Environment<span class="token punctuation">.</span>get<span class="token punctuation">(</span>workspace<span class="token operator">=</span>ws<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'training_environment'</span><span class="token punctuation">)</span>

estimator <span class="token operator">=</span> Estimator<span class="token punctuation">(</span>source_directory<span class="token operator">=</span><span class="token string">'experiment_folder'</span><span class="token punctuation">,</span>
                      entry_script<span class="token operator">=</span><span class="token string">'training_script.py'</span><span class="token punctuation">,</span>
                      environment_definition<span class="token operator">=</span>training_env<span class="token punctuation">,</span>
                      compute_target<span class="token operator">=</span>compute_name<span class="token punctuation">)</span>
</code></pre></div><h2 id="pipelines"><a href="#pipelines" class="header-anchor">#</a> Pipelines</h2> <p>In Azure Machine Learning, a <code>pipeline</code> is a workflow of machine learning tasks in which each task is implemented as a <code>step</code>. Steps can be arranged sequentially or in parallel, enabling you to build sophisticated flow logic to orchestrate machine learning operations. Each step can be run on a specific compute target, making it possible to combine different types of processing as required to achieve an overall goal.</p> <p>A pipeline can be executed as a process by running the pipeline as an experiment. Each step in the pipeline runs on its allocated compute target as part of the overall experiment run.</p> <p><strong>Note:</strong> You can publish a pipeline as a REST endpoint, enabling client applications to initiate a pipeline run. You can also define a schedule for a pipeline, and have it run automatically at periodic intervals</p> <h3 id="pipeline-steps"><a href="#pipeline-steps" class="header-anchor">#</a> Pipeline Steps</h3> <p>To create a pipeline, you must first define each step and then create a pipeline that includes the steps. The specific configuration of each step depends on the step type. These the sames as the modules seen in the Drag&amp;Drop interface.</p> <p>For example, pipeline for <strong>PythonScriptStep</strong>:</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">from</span> azureml<span class="token punctuation">.</span>pipeline<span class="token punctuation">.</span>steps <span class="token keyword">import</span> PythonScriptStep<span class="token punctuation">,</span> EstimatorStep

<span class="token comment"># Step to run a Python script</span>
step1 <span class="token operator">=</span> PythonScriptStep<span class="token punctuation">(</span>name <span class="token operator">=</span> <span class="token string">'prepare data'</span><span class="token punctuation">,</span>
                         source_directory <span class="token operator">=</span> <span class="token string">'scripts'</span><span class="token punctuation">,</span>
                         script_name <span class="token operator">=</span> <span class="token string">'data_prep.py'</span><span class="token punctuation">,</span>
                         compute_target <span class="token operator">=</span> <span class="token string">'aml-cluster'</span><span class="token punctuation">,</span>
                         runconfig <span class="token operator">=</span> run_config<span class="token punctuation">)</span>

<span class="token comment"># Step to run an estimator</span>
step2 <span class="token operator">=</span> EstimatorStep<span class="token punctuation">(</span>name <span class="token operator">=</span> <span class="token string">'train model'</span><span class="token punctuation">,</span>
                      estimator <span class="token operator">=</span> sk_estimator<span class="token punctuation">,</span>
                      compute_target <span class="token operator">=</span> <span class="token string">'aml-cluster'</span><span class="token punctuation">)</span>
</code></pre></div><p>Once defined, the pipeline can be built</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">from</span> azureml<span class="token punctuation">.</span>pipeline<span class="token punctuation">.</span>core <span class="token keyword">import</span> Pipeline
<span class="token keyword">from</span> azureml<span class="token punctuation">.</span>core <span class="token keyword">import</span> Experiment

<span class="token comment"># Construct the pipeline</span>
train_pipeline <span class="token operator">=</span> Pipeline<span class="token punctuation">(</span>workspace <span class="token operator">=</span> ws<span class="token punctuation">,</span> steps <span class="token operator">=</span> <span class="token punctuation">[</span>step1<span class="token punctuation">,</span>step2<span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># Create an experiment and run the pipeline</span>
experiment <span class="token operator">=</span> Experiment<span class="token punctuation">(</span>workspace <span class="token operator">=</span> ws<span class="token punctuation">,</span> name <span class="token operator">=</span> <span class="token string">'training-pipeline'</span><span class="token punctuation">)</span>
pipeline_run <span class="token operator">=</span> experiment<span class="token punctuation">.</span>submit<span class="token punctuation">(</span>train_pipeline<span class="token punctuation">)</span>
</code></pre></div><h4 id="passing-data-between-steps"><a href="#passing-data-between-steps" class="header-anchor">#</a> Passing Data Between Steps</h4> <p>Using the <code>PipelineData</code> object you can pass data from one step to another, this is a special kind of <code>DataReference</code>,</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">from</span> azureml<span class="token punctuation">.</span>pipeline<span class="token punctuation">.</span>core <span class="token keyword">import</span> PipelineData
<span class="token keyword">from</span> azureml<span class="token punctuation">.</span>pipeline<span class="token punctuation">.</span>steps <span class="token keyword">import</span> PythonScriptStep<span class="token punctuation">,</span> EstimatorStep

<span class="token comment"># Get a dataset for the initial data</span>
raw_ds <span class="token operator">=</span> Dataset<span class="token punctuation">.</span>get_by_name<span class="token punctuation">(</span>ws<span class="token punctuation">,</span> <span class="token string">'raw_dataset'</span><span class="token punctuation">)</span>

<span class="token comment"># Define a PipelineData object to pass data between steps</span>
data_store <span class="token operator">=</span> ws<span class="token punctuation">.</span>get_default_datastore<span class="token punctuation">(</span><span class="token punctuation">)</span>
prepped_data <span class="token operator">=</span> PipelineData<span class="token punctuation">(</span><span class="token string">'prepped'</span><span class="token punctuation">,</span>  datastore<span class="token operator">=</span>data_store<span class="token punctuation">)</span>

<span class="token comment"># Step to run a Python script</span>
step1 <span class="token operator">=</span> PythonScriptStep<span class="token punctuation">(</span>name <span class="token operator">=</span> <span class="token string">'prepare data'</span><span class="token punctuation">,</span>
                         source_directory <span class="token operator">=</span> <span class="token string">'scripts'</span><span class="token punctuation">,</span>
                         script_name <span class="token operator">=</span> <span class="token string">'data_prep.py'</span><span class="token punctuation">,</span>
                         compute_target <span class="token operator">=</span> <span class="token string">'aml-cluster'</span><span class="token punctuation">,</span>
                         runconfig <span class="token operator">=</span> run_config<span class="token punctuation">,</span>
                         <span class="token comment"># Specify dataset as initial input</span>
                         inputs<span class="token operator">=</span><span class="token punctuation">[</span>raw_ds<span class="token punctuation">.</span>as_named_input<span class="token punctuation">(</span><span class="token string">'raw_data'</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                         <span class="token comment"># Specify PipelineData as output</span>
                         outputs<span class="token operator">=</span><span class="token punctuation">[</span>prepped_data<span class="token punctuation">]</span><span class="token punctuation">,</span>
                         <span class="token comment"># Also pass as data reference to script</span>
                         arguments <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'--folder'</span><span class="token punctuation">,</span> prepped_data<span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># Step to run an estimator</span>
step2 <span class="token operator">=</span> EstimatorStep<span class="token punctuation">(</span>name <span class="token operator">=</span> <span class="token string">'train model'</span><span class="token punctuation">,</span>
                      estimator <span class="token operator">=</span> sk_estimator<span class="token punctuation">,</span>
                      compute_target <span class="token operator">=</span> <span class="token string">'aml-cluster'</span><span class="token punctuation">,</span>
                      <span class="token comment"># Specify PipelineData as input</span>
                      inputs<span class="token operator">=</span><span class="token punctuation">[</span>prepped_data<span class="token punctuation">]</span><span class="token punctuation">,</span>
                      <span class="token comment"># Pass as data reference to estimator script</span>
                      estimator_entry_script_arguments<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'--folder'</span><span class="token punctuation">,</span> prepped_data<span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre></div><h4 id="pipeline-step-reuse"><a href="#pipeline-step-reuse" class="header-anchor">#</a> Pipeline Step Reuse</h4> <p>Pipelines with multiple long-running steps can take a significant time to complete, so Azure Machine Learning includes some default caching and reuse features to reduce this time. By default the step output from a previous pipeline run is reused without re-running the step as long as the script, source directory, and other parameters for the step have not changed. This can significantly reduce the time it takes to run a pipeline; however it can lead to stale results when changes to downstream data sources have not been accounted for.</p> <p>To control reuse for an individual step, you can set the <code>allow_reuse</code> parameter in the step configuration, like this:</p> <div class="language-python extra-class"><pre class="language-python"><code>step1 <span class="token operator">=</span> PythonScriptStep<span class="token punctuation">(</span>name <span class="token operator">=</span> <span class="token string">'prepare data'</span><span class="token punctuation">,</span>
                         source_directory <span class="token operator">=</span> <span class="token string">'scripts'</span><span class="token punctuation">,</span>
                         script_name <span class="token operator">=</span> <span class="token string">'data_prep.py'</span><span class="token punctuation">,</span>
                         compute_target <span class="token operator">=</span> <span class="token string">'aml-cluster'</span><span class="token punctuation">,</span>
                         runconfig <span class="token operator">=</span> run_config<span class="token punctuation">,</span>
                         inputs<span class="token operator">=</span><span class="token punctuation">[</span>raw_ds<span class="token punctuation">.</span>as_named_input<span class="token punctuation">(</span><span class="token string">'raw_data'</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                         outputs<span class="token operator">=</span><span class="token punctuation">[</span>prepped_data<span class="token punctuation">]</span><span class="token punctuation">,</span>
                         arguments <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'--folder'</span><span class="token punctuation">,</span> prepped_data<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                         <span class="token comment"># Disable step reuse</span>
                         allow_reuse <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">)</span>
</code></pre></div><p>This can be overwritten by forcing all steps to be reused.</p> <div class="language-python extra-class"><pre class="language-python"><code>pipeline_run <span class="token operator">=</span> experiment<span class="token punctuation">.</span>submit<span class="token punctuation">(</span>train_pipeline<span class="token punctuation">,</span> regenerate_outputs<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
</code></pre></div></div> <footer class="page-edit"><!----> <!----></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/guide/certifications/azure_dp_100/dp100_pt1.html" class="prev">
        Azure DP-100 Day 1
      </a></span> <span class="next"><a href="/guide/certifications/azure_dp_100/dp100_pt3.html">
        Azure DP-100 Day 3
      </a>
      →
    </span></p></div> </main></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.4a47de2e.js" defer></script><script src="/assets/js/2.c8d9d072.js" defer></script><script src="/assets/js/48.2d3aeb95.js" defer></script>
  </body>
</html>
