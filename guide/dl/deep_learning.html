<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Deep Learning (ANN) | Juan Daza</title>
    <meta name="generator" content="VuePress 1.8.0">
    <link rel="apple-touch-icon" sizes="180x180" href="/favicons/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/favicons/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicons/favicon-16x16.png">
    <link rel="manifest" href="/favicons/site.webmanifest">
    <meta name="description" content="Personal Site - Data Science">
    <meta name="msapplication-TileColor" content="#3a0839">
    <meta name="theme-color" content="#ffffff">
    
    <link rel="preload" href="/assets/css/0.styles.155411b8.css" as="style"><link rel="preload" href="/assets/js/app.6dcbb695.js" as="script"><link rel="preload" href="/assets/js/2.c8d9d072.js" as="script"><link rel="preload" href="/assets/js/47.dc4d6206.js" as="script"><link rel="prefetch" href="/assets/js/10.d1ce74f6.js"><link rel="prefetch" href="/assets/js/11.db0c7ded.js"><link rel="prefetch" href="/assets/js/12.0e8bfade.js"><link rel="prefetch" href="/assets/js/13.d2c3f67c.js"><link rel="prefetch" href="/assets/js/14.a5cb3f2e.js"><link rel="prefetch" href="/assets/js/15.ccfe6919.js"><link rel="prefetch" href="/assets/js/16.bb6c67c5.js"><link rel="prefetch" href="/assets/js/17.8686cb17.js"><link rel="prefetch" href="/assets/js/18.5ac61ac7.js"><link rel="prefetch" href="/assets/js/19.63f8f727.js"><link rel="prefetch" href="/assets/js/20.85f824be.js"><link rel="prefetch" href="/assets/js/21.d851bced.js"><link rel="prefetch" href="/assets/js/22.65608a33.js"><link rel="prefetch" href="/assets/js/23.148584a0.js"><link rel="prefetch" href="/assets/js/24.5dc4bc46.js"><link rel="prefetch" href="/assets/js/25.008d885c.js"><link rel="prefetch" href="/assets/js/26.f87d3c92.js"><link rel="prefetch" href="/assets/js/27.43852491.js"><link rel="prefetch" href="/assets/js/28.f20173de.js"><link rel="prefetch" href="/assets/js/29.41c2edc2.js"><link rel="prefetch" href="/assets/js/3.4039a9f7.js"><link rel="prefetch" href="/assets/js/30.c2a2e5eb.js"><link rel="prefetch" href="/assets/js/31.698f34ab.js"><link rel="prefetch" href="/assets/js/32.c564e0aa.js"><link rel="prefetch" href="/assets/js/33.1e31631f.js"><link rel="prefetch" href="/assets/js/34.a5418a15.js"><link rel="prefetch" href="/assets/js/35.b08d2e3f.js"><link rel="prefetch" href="/assets/js/36.1012756d.js"><link rel="prefetch" href="/assets/js/37.dd7f07cb.js"><link rel="prefetch" href="/assets/js/38.32740ce4.js"><link rel="prefetch" href="/assets/js/39.de74039d.js"><link rel="prefetch" href="/assets/js/4.1059787c.js"><link rel="prefetch" href="/assets/js/40.fae1444e.js"><link rel="prefetch" href="/assets/js/41.7b67a031.js"><link rel="prefetch" href="/assets/js/42.c8213427.js"><link rel="prefetch" href="/assets/js/43.b6e92082.js"><link rel="prefetch" href="/assets/js/44.af03683b.js"><link rel="prefetch" href="/assets/js/45.5e9f5793.js"><link rel="prefetch" href="/assets/js/46.fb9d886a.js"><link rel="prefetch" href="/assets/js/48.13378c7f.js"><link rel="prefetch" href="/assets/js/49.3c960ad3.js"><link rel="prefetch" href="/assets/js/5.cf6f72c1.js"><link rel="prefetch" href="/assets/js/50.c564b96f.js"><link rel="prefetch" href="/assets/js/51.59c25d8c.js"><link rel="prefetch" href="/assets/js/52.3eda2524.js"><link rel="prefetch" href="/assets/js/53.9a4b801a.js"><link rel="prefetch" href="/assets/js/54.c2217381.js"><link rel="prefetch" href="/assets/js/55.8182a208.js"><link rel="prefetch" href="/assets/js/56.c48d5e30.js"><link rel="prefetch" href="/assets/js/57.b404f9ca.js"><link rel="prefetch" href="/assets/js/58.e20632cf.js"><link rel="prefetch" href="/assets/js/59.64e34bdb.js"><link rel="prefetch" href="/assets/js/6.3c6a86b6.js"><link rel="prefetch" href="/assets/js/60.a7d7f19e.js"><link rel="prefetch" href="/assets/js/7.e1ae24ba.js"><link rel="prefetch" href="/assets/js/8.c0963d9f.js"><link rel="prefetch" href="/assets/js/9.18a35f9e.js">
    <link rel="stylesheet" href="/assets/css/0.styles.155411b8.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><img src="/photo.png" alt="Juan Daza" class="logo"> <span class="site-name can-hide">Juan Daza</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/home.html" class="nav-link">
  Home
</a></div><div class="nav-item"><a href="/cv.html" class="nav-link">
  CV
</a></div><div class="nav-item"><a href="https://www.linkedin.com/in/juandanieldaza" target="_blank" rel="noopener noreferrer" class="nav-link external">
  LinkedIn
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/home.html" class="nav-link">
  Home
</a></div><div class="nav-item"><a href="/cv.html" class="nav-link">
  CV
</a></div><div class="nav-item"><a href="https://www.linkedin.com/in/juandanieldaza" target="_blank" rel="noopener noreferrer" class="nav-link external">
  LinkedIn
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div> <!----></nav>  <ul class="sidebar-links"><li><a href="/" aria-current="page" class="sidebar-link">Home</a></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Help Snippets</span> <span class="arrow right"></span></p> <!----></section></li><li><a href="/guide/algos/" class="sidebar-link">Machine Learning</a></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading open"><span>Machine Learning</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/guide/algos/MLlist.html" class="sidebar-link">Algorithms Table</a></li><li><a href="/guide/dl/deep_learning.html" aria-current="page" class="active sidebar-link">Deep Learning (ANN)</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/guide/dl/deep_learning.html#ann-general-concepts" class="sidebar-link">ANN General Concepts</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/guide/dl/deep_learning.html#multilayer-perceptron-backpropagation" class="sidebar-link">Multilayer Perceptron &amp; Backpropagation</a></li></ul></li><li class="sidebar-sub-header"><a href="/guide/dl/deep_learning.html#important-concepts" class="sidebar-link">Important Concepts</a></li></ul></li><li><a href="/guide/algos/NLP.html" class="sidebar-link">NLP</a></li></ul></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Graphs</span> <span class="arrow right"></span></p> <!----></section></li><li><a href="/guide/mlops/" class="sidebar-link">ML OPS</a></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Ml Ops</span> <span class="arrow right"></span></p> <!----></section></li><li><a href="/guide/certifications/" class="sidebar-link">Cloud Certification</a></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>AWS SA</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Azure ML DP-100</span> <span class="arrow right"></span></p> <!----></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="deep-learning-ann"><a href="#deep-learning-ann" class="header-anchor">#</a> Deep Learning (ANN)</h1> <p></p><div class="table-of-contents"><ul><li><a href="#ann-general-concepts">ANN General Concepts</a><ul><li><a href="#multilayer-perceptron-backpropagation">Multilayer Perceptron &amp; Backpropagation</a></li></ul></li><li><a href="#important-concepts">Important Concepts</a></li></ul></div><p></p> <h2 id="ann-general-concepts"><a href="#ann-general-concepts" class="header-anchor">#</a> ANN General Concepts</h2> <h3 id="multilayer-perceptron-backpropagation"><a href="#multilayer-perceptron-backpropagation" class="header-anchor">#</a> Multilayer Perceptron &amp; Backpropagation</h3> <p><strong>MLP</strong></p> <p>MLP -&gt; composed of one input layer, one or more TLU (hidden layers), and one final TLU (output layer).</p> <p><strong>Backpropagation</strong></p> <ul><li>Handles one mini-batch at a time, goes through the full training set multiple times (called <em>epoch</em>)</li> <li>Computes the <em>forward pass</em> -&gt; Computes the output of all neurons in the first layer, then it passes the result to the next layer and so on. Like making predictions but results are preserved</li> <li>Calculates the network's output error</li> <li>Then, it computes how much each output connection contributed to the error</li> <li>Measures how much of these error contributions came from each connection in the layer below, working backwards.</li> <li>Finally, it does Gradient Descent.</li></ul> <p><strong>Regression MLP</strong></p> <p>Use single output neuron or an output neuron per dimension.</p> <ul><li>Guarantee Output is &gt; 0 -&gt; ReLU Activation function or SoftPlus</li> <li>Guarantee output is in range (a,b) -&gt; Logistic or Hyperbolic tangent and scale.</li></ul> <p><em>Typical Regression MLP</em></p> <table><thead><tr><th style="text-align:center;">Hyperparameter</th> <th style="text-align:center;">Typical Value</th></tr></thead> <tbody><tr><td style="text-align:center;"># input neurons</td> <td style="text-align:center;">One per input feature Value</td></tr> <tr><td style="text-align:center;"># hidden layers</td> <td style="text-align:center;">1-5</td></tr> <tr><td style="text-align:center;"># neurons per hidden layer</td> <td style="text-align:center;">10-100</td></tr> <tr><td style="text-align:center;"># output neurons</td> <td style="text-align:center;">1 per dimension</td></tr> <tr><td style="text-align:center;">Hidden activation</td> <td style="text-align:center;">ReLU/SELU</td></tr> <tr><td style="text-align:center;">Output activation</td> <td style="text-align:center;">None, ReLU/SoftPlus/Logistic/tanh</td></tr> <tr><td style="text-align:center;">Loss function</td> <td style="text-align:center;">MSE or MAE/Huber (if outliers)</td></tr></tbody></table> <p><strong>Classification MLP</strong></p> <ul><li>Binary -&gt; Single output Neuron using logistic</li> <li>Multilabel Binary -&gt; One output neuron per positive label</li> <li>Multiclass -&gt; One output Neuron per class</li></ul> <p><em>Typical Classification MLP</em></p> <table><thead><tr><th style="text-align:center;">Hyperparameter</th> <th style="text-align:center;">Binary</th> <th style="text-align:center;">Multilabel</th> <th style="text-align:center;">Multiclass</th></tr></thead> <tbody><tr><td style="text-align:center;"># input neurons</td> <td style="text-align:center;">One per input feature Value</td> <td style="text-align:center;">One per input feature Value</td> <td style="text-align:center;">One per input feature Value</td></tr> <tr><td style="text-align:center;"># hidden layers</td> <td style="text-align:center;">1-5</td> <td style="text-align:center;">1-5</td> <td style="text-align:center;">1-5</td></tr> <tr><td style="text-align:center;"># neurons per hidden layer</td> <td style="text-align:center;">10-100</td> <td style="text-align:center;">10-100</td> <td style="text-align:center;">10-100</td></tr> <tr><td style="text-align:center;"># output neurons</td> <td style="text-align:center;">1</td> <td style="text-align:center;">1 per label</td> <td style="text-align:center;">1 per class</td></tr> <tr><td style="text-align:center;">Output activation</td> <td style="text-align:center;">Logistic</td> <td style="text-align:center;">Logistic</td> <td style="text-align:center;">SoftMax</td></tr> <tr><td style="text-align:center;">Loss function</td> <td style="text-align:center;">Cross entropy</td> <td style="text-align:center;">Cross entropy</td> <td style="text-align:center;">Cross entropy</td></tr></tbody></table> <div class="custom-block tip"><p class="custom-block-title">In Keras</p> <p>sparse_categorical_crossentropy -&gt; Sparse labels</p> <p>categorical_crossentropy -&gt; One target probability per class</p> <p>sigmoid (logistic) -&gt; Binary classification</p></div> <p><strong>Other Topologies/Architectures</strong></p> <ul><li><a href="https://arxiv.org/abs/1606.07792" target="_blank" rel="noopener noreferrer"><em>Wide &amp; Deep</em><span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> -&gt; Non sequential neural network</li></ul> <h2 id="important-concepts"><a href="#important-concepts" class="header-anchor">#</a> Important Concepts</h2> <p><strong>Vanishing Gradient Problem</strong></p> <p>Gradients often get smaller and smaller as the algorithm progresses down to the lower layers. As a result, the Gradient Descent update leaves the lower layers’ connection weights virtually unchanged, and training never converges to a good solution.</p> <p>A solution is <code>Glorot Initialization</code> or <code>He Initialization</code>.</p> <div class="language-python extra-class"><pre class="language-python"><code>    <span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span>
    keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> kernel_initializer<span class="token operator">=</span><span class="token string">&quot;he_normal&quot;</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span>alpha<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span>
</code></pre></div><p><strong>Batch Normalization</strong></p> <p>Consists of adding an operation in the model just before or after the activation function of each hidden layer. This operation simply zero-centers and normalizes each input, then scales and shifts the result using two new parameter vectors per layer: one for scaling, the other for shifting.</p> <div class="language-python extra-class"><pre class="language-python"><code>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>BatchNormalization<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div><p><strong>Regularization</strong></p> <p><strong>L1 L2</strong></p> <p><code>L1 &amp; L2</code> to constrain a neural network’s connection weights or get a sparse model.</p> <div class="language-python extra-class"><pre class="language-python"><code>layer <span class="token operator">=</span> keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">&quot;elu&quot;</span><span class="token punctuation">,</span>
                           kernel_initializer<span class="token operator">=</span><span class="token string">&quot;he_normal&quot;</span><span class="token punctuation">,</span>
                           kernel_regularizer<span class="token operator">=</span>keras<span class="token punctuation">.</span>regularizers<span class="token punctuation">.</span>l2<span class="token punctuation">(</span><span class="token number">0.01</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><p><a href="https://jmlr.org/papers/v15/srivastava14a.html" target="_blank" rel="noopener noreferrer"><strong>Dropout</strong><span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>At every training step, every neuron (including the input neurons, but always excluding the output neurons) has a probability p of being temporarily <code>dropped out</code>, meaning it will be entirely ignored during this training step, but it may be active during the next step.</p> <div class="language-python extra-class"><pre class="language-python"><code>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
    keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>rate<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
</code></pre></div></div> <footer class="page-edit"><!----> <!----></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/guide/algos/MLlist.html" class="prev">
        Algorithms Table
      </a></span> <span class="next"><a href="/guide/algos/NLP.html">
        NLP
      </a>
      →
    </span></p></div> </main></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.6dcbb695.js" defer></script><script src="/assets/js/2.c8d9d072.js" defer></script><script src="/assets/js/47.dc4d6206.js" defer></script>
  </body>
</html>
