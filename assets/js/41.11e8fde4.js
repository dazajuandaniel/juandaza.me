(window.webpackJsonp=window.webpackJsonp||[]).push([[41],{316:function(t,s,a){"use strict";a.r(s);var n=a(14),e=Object(n.a)({},(function(){var t=this,s=t._self._c;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h1",{attrs:{id:"azure-dp-100-module-3"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#azure-dp-100-module-3"}},[t._v("#")]),t._v(" Azure DP-100 Module 3")]),t._v(" "),s("h2",{attrs:{id:"running-experiments-and-training-models"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#running-experiments-and-training-models"}},[t._v("#")]),t._v(" Running Experiments and Training Models")]),t._v(" "),s("p",[t._v("In AMZL, an experiment is a named process (running a file or a script) that generates outputs.")]),t._v(" "),s("h3",{attrs:{id:"the-run-context"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#the-run-context"}},[t._v("#")]),t._v(" The "),s("code",[t._v("Run Context")])]),t._v(" "),s("p",[t._v("The "),s("code",[t._v("run context")]),t._v(" is used to start/end an experiment. Once completed results are visibile in AML Studio")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("experiment "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Experiment"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("worskpace "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ws"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" name "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'my_exp'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nrun "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" experiment"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("start_logging"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n\nrun"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("complete"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h3",{attrs:{id:"logging-metrics-outputs"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#logging-metrics-outputs"}},[t._v("#")]),t._v(" Logging Metrics & Outputs")]),t._v(" "),s("p",[t._v("The "),s("code",[t._v("Run")]),t._v(" object provides logging functions:")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("log")]),t._v(": Single named value")]),t._v(" "),s("li",[s("code",[t._v("log_list")]),t._v(": Named list of values")]),t._v(" "),s("li",[s("code",[t._v("log_row")]),t._v(": Row with multiple columns")]),t._v(" "),s("li",[s("code",[t._v("log_table")]),t._v(": Dictionary as a table")]),t._v(" "),s("li",[s("code",[t._v("log_image")]),t._v(": Log Image or plot")])]),t._v(" "),s("p",[s("strong",[t._v("Note")])]),t._v(" "),s("p",[s("code",[t._v("ML Flow")]),t._v(" can be used in conjuction with AML, see "),s("a",{attrs:{href:"https://docs.microsoft.com/en-us/azure/machine-learning/how-to-use-mlflow",target:"_blank",rel:"noopener noreferrer"}},[t._v("docs"),s("OutboundLink")],1)]),t._v(" "),s("h3",{attrs:{id:"retrieving-logged-metrics"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#retrieving-logged-metrics"}},[t._v("#")]),t._v(" Retrieving Logged Metrics")]),t._v(" "),s("p",[t._v("The "),s("code",[t._v("RunDetails")]),t._v(" object provides widget capability in a notebook to view metrics")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" azureml"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("widgets "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" RunDetails\n\nRunDetails"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("run"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Metrics can also be retrieved using the run object")]),t._v("\nmetrics "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" run"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_metrics"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h3",{attrs:{id:"output"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#output"}},[t._v("#")]),t._v(" Output")]),t._v(" "),s("p",[t._v("Output files are saved in the "),s("code",[t._v("outputs")]),t._v(" folder and it can be done by using the "),s("code",[t._v("run")]),t._v(" object.")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("run"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("upload_file"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'outputs/sample.csv'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" path_or_stream"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'./sample.csv'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# To get the list of outputs")]),t._v("\nfiles "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" run"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_file_names"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h3",{attrs:{id:"running-a-script-as-an-experiment"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#running-a-script-as-an-experiment"}},[t._v("#")]),t._v(" Running a Script as an Experiment")]),t._v(" "),s("p",[t._v("When running from a script, to access the experiment run context, the "),s("strong",[t._v("script")]),t._v(" needs to have the "),s("code",[t._v("azureml.core.Run")]),t._v(" class imported and call the "),s("code",[t._v("get_context")]),t._v(" method.")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" azureml"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("core "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Run\nrun "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Run"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_context"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\nrun"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("complete"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h3",{attrs:{id:"running-an-experiment-script"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#running-an-experiment-script"}},[t._v("#")]),t._v(" Running an Experiment Script")]),t._v(" "),s("p",[t._v("A  "),s("code",[t._v("script configuration")]),t._v(" is required to define the script to be run and the environment in which it'll run, this is achieved using the "),s("code",[t._v("ScriptRunConfig")]),t._v(" object.")]),t._v(" "),s("p",[t._v("To associate a script with a RunConfig, you must use a ScriptRunConfig object.")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" azureml"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("core "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Experiment"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ScriptRunConfig\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Create a script config")]),t._v("\nscript_config "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ScriptRunConfig"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("source_directory"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("experiment_folder"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                                script"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'experiment.py'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# submit the experiment")]),t._v("\nexperiment "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Experiment"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("workspace "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ws"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" name "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'my-experiment'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nrun "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" experiment"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("submit"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("config"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("script_config"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nrun"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("wait_for_completion"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("show_output"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[s("strong",[t._v("Note")])]),t._v(" "),s("p",[t._v("If your script depends on packages that are not included in the default environment, you must associate the "),s("code",[t._v("ScriptRunConfig")]),t._v(" with an Environment object that makes use of a "),s("code",[t._v("CondaDependencies")]),t._v(" object to specify the Python packages required.")]),t._v(" "),s("h2",{attrs:{id:"training-and-registering-models"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#training-and-registering-models"}},[t._v("#")]),t._v(" Training and Registering Models")]),t._v(" "),s("h3",{attrs:{id:"estimators"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#estimators"}},[t._v("#")]),t._v(" Estimators")]),t._v(" "),s("p",[t._v("AML provides an "),s("code",[t._v("Estimator")]),t._v(" class that combines a "),s("code",[t._v("run configuration")]),t._v(" and a "),s("code",[t._v("script configuration")]),t._v(" in a single object to make it easy to run Scripts (removes the need to manage packages).")]),t._v(" "),s("p",[t._v("Link to "),s("a",{attrs:{href:"https://docs.microsoft.com/en-us/azure/machine-learning/how-to-set-up-training-targets",target:"_blank",rel:"noopener noreferrer"}},[t._v("docs"),s("OutboundLink")],1)]),t._v(" "),s("h3",{attrs:{id:"writing-a-script-to-train-a-model"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#writing-a-script-to-train-a-model"}},[t._v("#")]),t._v(" Writing a Script to train a Model")]),t._v(" "),s("p",[t._v("The script should save the trained model in the outputs folder.")]),t._v(" "),s("p",[t._v("Example training script below:")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" azureml"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("core "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Run\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pandas "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" pd\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" numpy "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" np\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" joblib\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" sklearn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("model_selection "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" train_test_split\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" sklearn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("linear_model "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" LogisticRegression\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Get the experiment run context")]),t._v("\nrun "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Run"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_context"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n\nmodel "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" LogisticRegression"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("C"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("reg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" solver"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"liblinear"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fit"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X_train"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y_train"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Save the trained model")]),t._v("\nos"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("makedirs"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'outputs'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" exist_ok"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\njoblib"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dump"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("value"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" filename"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'outputs/model.pkl'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nrun"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("complete"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("Then using the estimator, you can run the script quite easily and define the "),s("code",[t._v("run configuration")]),t._v(".")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" azureml"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("train"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("estimator "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Estimator\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" azureml"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("core "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Experiment\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Create an estimator")]),t._v("\nestimator "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Estimator"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("source_directory"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'experiment_folder'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                      entry_script"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'training_script.py'")]),t._v("\n                      compute_target"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'local'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                      conda_packages"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'scikit-learn'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n                      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Create and run an experiment")]),t._v("\nexperiment "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Experiment"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("workspace "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ws"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" name "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'training_experiment'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nrun "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" experiment"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("submit"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("config"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("estimator"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[s("strong",[t._v("Notes")])]),t._v(" "),s("p",[t._v("You can use the framework specific estimators and it will have the required conda packages pre-installed.")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" azureml"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("train"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sklearn "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" SKLearn\n\nestimator "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" SKLearn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("source_directory"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'experiment_folder'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                    entry_script"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'training_script.py'")]),t._v("\n                    compute_target"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'local'")]),t._v("\n                    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h3",{attrs:{id:"script-parameters"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#script-parameters"}},[t._v("#")]),t._v(" Script Parameters")]),t._v(" "),s("p",[t._v("The library "),s("code",[t._v("arparse")]),t._v(" has to be used to read the arguments passed to the script.")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" azureml"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("core "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Run\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" argparse\n\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Get the experiment run context")]),t._v("\nrun "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Run"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_context"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Set regularization hyperparameter")]),t._v("\nparser "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" argparse"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ArgumentParser"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nparser"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_argument"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'--reg_rate'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("type")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("float")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dest"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'reg'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" default"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.01")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nargs "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" parser"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parse_args"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nreg "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" args"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reg\n\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Train a logistic regression model")]),t._v("\nmodel "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" LogisticRegression"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("C"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("reg"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" solver"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"liblinear"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fit"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X_train"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y_train"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Save the trained model")]),t._v("\nos"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("makedirs"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'outputs'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" exist_ok"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\njoblib"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dump"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("value"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" filename"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'outputs/model.pkl'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nrun"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("complete"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("The estimator can also receive the parameters by using the "),s("code",[t._v("script_params")]),t._v(" value.")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Create an estimator")]),t._v("\nestimator "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" SKLearn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("source_directory"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'experiment_folder'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                    entry_script"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'training_script.py'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                    script_params "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'--reg_rate'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                    compute_target"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'local'")]),t._v("\n                    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h3",{attrs:{id:"registering-a-trained-model"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#registering-a-trained-model"}},[t._v("#")]),t._v(" Registering a Trained Model")]),t._v(" "),s("p",[t._v("The "),s("code",[t._v("Run")]),t._v(" object can be used to retrieve outputs including models. The "),s("code",[t._v("get_file_names")]),t._v(" lists all the files generated and you can use the "),s("code",[t._v("download_file")]),t._v("/"),s("code",[t._v("download_files")]),t._v(" to download the output files in the local file system.")]),t._v(" "),s("h4",{attrs:{id:"registering-a-model"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#registering-a-model"}},[t._v("#")]),t._v(" Registering a Model")]),t._v(" "),s("p",[t._v("AML provides the ability to register and keep track of models and their versions and use this for inferencing. It is done using the "),s("code",[t._v("register")]),t._v(" method of the "),s("code",[t._v("Model")]),t._v(" object.")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" azureml"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("core "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Model\n\nmodel "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("register"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("workspace"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("ws"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                       model_name"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'classification_model'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                       model_path"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'model.pkl'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# local path")]),t._v("\n                       description"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'A classification model'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                       tags"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'dept'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'sales'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                       model_framework"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("Model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Framework"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("SCIKITLEARN"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                       model_framework_version"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'0.20.3'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# To view the models")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" model "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" Model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("list")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ws"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Get model name and auto-generated version")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'version:'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("version"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])])}),[],!1,null,null,null);s.default=e.exports}}]);