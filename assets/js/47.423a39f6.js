(window.webpackJsonp=window.webpackJsonp||[]).push([[47],{322:function(t,a,n){"use strict";n.r(a);var s=n(14),e=Object(s.a)({},(function(){var t=this,a=t._self._c;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"azure-dp-100-module-9"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#azure-dp-100-module-9"}},[t._v("#")]),t._v(" Azure DP-100 Module 9")]),t._v(" "),a("h2",{attrs:{id:"model-interpretability"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#model-interpretability"}},[t._v("#")]),t._v(" Model Interpretability")]),t._v(" "),a("p",[t._v("Based on the "),a("code",[t._v("Interpret-Community")]),t._v(" package.")]),t._v(" "),a("h3",{attrs:{id:"global-and-local-feature-importance"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#global-and-local-feature-importance"}},[t._v("#")]),t._v(" Global and Local Feature Importance")]),t._v(" "),a("p",[a("code",[t._v("Global feature")]),t._v(" importance quantifies the relative importance of each feature in the test dataset as a whole.")]),t._v(" "),a("p",[a("code",[t._v("Local feature")]),t._v(" importance measures the influence of each feature value for a specific individual prediction.")]),t._v(" "),a("h3",{attrs:{id:"automl-learning-explanations"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#automl-learning-explanations"}},[t._v("#")]),t._v(" AutoML Learning Explanations")]),t._v(" "),a("p",[t._v("To generate model explanations when using automated machine learning, you must enable model explainability.")]),t._v(" "),a("p",[t._v("To generate explanations you can:")]),t._v(" "),a("ul",[a("li",[t._v("Select the Explain best model configuration setting in the user interface.")]),t._v(" "),a("li",[t._v("Specify the "),a("code",[t._v("model_explanaibility")]),t._v(" option in the "),a("code",[t._v("AutoMLConfig")]),t._v(" object in the SDK"),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("automl_config "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" AutoMLConfig"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Automated ML Experiment'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                            "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# <other configuration settings here...>")]),t._v("\n                            model_explainability"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("\n                            "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])])]),t._v(" "),a("p",[t._v("To view the explanations you can:")]),t._v(" "),a("ul",[a("li",[t._v("Open the experiment run in Studio and go to the "),a("code",[t._v("explanations")]),t._v(" tab")]),t._v(" "),a("li",[t._v("Use the "),a("code",[t._v("RunDetails")]),t._v(" widget to view an automated run in Jupyter")]),t._v(" "),a("li",[t._v("Use the "),a("code",[t._v("ExplanationClient")]),t._v(" class in the SDK"),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" azureml"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("contrib"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("interpret"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("explanation"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("explanation_client "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" ExplanationClient\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Get the best model (2nd item in outputs)")]),t._v("\nbest_run"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" fitted_model "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" automl_run"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_output"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Get the feature explanations")]),t._v("\nclient "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ExplanationClient"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_run"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("best_run"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nexplanation "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" client"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("download_model_explanation"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nfeature_importances "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" explanation"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_feature_importance_dict"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])])]),t._v(" "),a("p",[a("strong",[t._v("Note:")]),t._v(" When "),a("code",[t._v("featurization")]),t._v(" is enabled for automated machine learning, the explanation includes the importance of the engineered features.")]),t._v(" "),a("h2",{attrs:{id:"model-explainers"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#model-explainers"}},[t._v("#")]),t._v(" Model Explainers")]),t._v(" "),a("p",[t._v("AML SDK can be used to create explianers for local models, even if they were not trained using AML experiments. It can be done by using the "),a("code",[t._v("azureml-interpret")]),t._v(" package")]),t._v(" "),a("p",[t._v("Types of explainers:")]),t._v(" "),a("ul",[a("li",[a("code",[t._v("MimicExplainer")]),t._v(": creates a global surrogate model")]),t._v(" "),a("li",[a("code",[t._v("TabularExplainer")]),t._v(": acts as a wrapper around various SHAP explainer algorithms")]),t._v(" "),a("li",[a("code",[t._v("PFIExplainer")]),t._v(": "),a("strong",[t._v("P")]),t._v("ermutation "),a("strong",[t._v("F")]),t._v("eature "),a("strong",[t._v("I")]),t._v("mportance explainer that analyzes feature importance by shuffling feature values and measuring the impact on prediction performance")])]),t._v(" "),a("p",[t._v("Example for Mimic Explainer")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" interpret"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ext"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("blackbox "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" MimicExplainer\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" interpret"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ext"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("glassbox "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" DecisionTreeExplainableModel\n\nmim_explainer "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" MimicExplainer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("model"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("loan_model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                               initialization_examples"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("X_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                               explainable_model "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" DecisionTreeExplainableModel"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                               features"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'loan_amount'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'income'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'age'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'marital_status'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                               classes"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'reject'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'approve'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("h3",{attrs:{id:"adding-interpretability-to-training-experiments"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#adding-interpretability-to-training-experiments"}},[t._v("#")]),t._v(" Adding Interpretability to Training Experiments")]),t._v(" "),a("p",[t._v("Both packages are required "),a("code",[t._v("azureml-interpret")]),t._v(" and "),a("code",[t._v("azureml-contrib-interpret")])]),t._v(" "),a("p",[t._v("To include an explanation in the run details, the training script must use the ExplanationClient.upload_model_explanation method to upload the explanation created by an Explainer.")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Import Azure ML run library")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" azureml"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("core"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("run "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Run\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" azureml"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("contrib"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("interpret"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("explanation"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("explanation_client "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" ExplanationClient\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" interpret"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ext"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("blackbox "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" TabularExplainer\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# other imports as required")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Get the experiment run context")]),t._v("\nrun "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Run"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_context"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# code to train model goes here")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Get explanation")]),t._v("\nexplainer "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" TabularExplainer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" X_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" features"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("features"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" classes"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("labels"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nexplanation "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" explainer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("explain_global"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Get an Explanation Client and upload the explanation")]),t._v("\nexplain_client "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ExplanationClient"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_run"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("run"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nexplain_client"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("upload_model_explanation"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("explanation"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" comment"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Tabular Explanation'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Complete the run")]),t._v("\nrun"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("complete"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("h3",{attrs:{id:"adding-interpretability-to-inferencing"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#adding-interpretability-to-inferencing"}},[t._v("#")]),t._v(" Adding Interpretability to Inferencing")]),t._v(" "),a("p",[t._v("First create a scoring explainer and add it to the "),a("code",[t._v("run(raw_data)")]),t._v(" function")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" interpret"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ext"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("blackbox "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" TabularExplainer\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" azureml"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("interpret"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("scoring"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("scoring_explainer "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" KernelScoringExplainer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" save\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" azureml"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("core "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Model\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Get a registered model")]),t._v("\nloan_model "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" ws"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("models"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'loan_model'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\ntab_explainer "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" TabularExplainer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("model "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" loan_model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                             initialization_examples"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("X_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                             features"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'loan_amount'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'income'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'age'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'marital_status'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                             classes"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'reject'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'approve'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Create and save a scoring explainer")]),t._v("\nscoring_explainer "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" KernelScoringExplainer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tab_explainer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" X_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nsave"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("scoring_explainer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" directory"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'explainer'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" exist_ok"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Register the explainer (like a model)")]),t._v("\nModel"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("register"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ws"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" model_name"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'loan_explainer'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'explainer/scoring_explainer.pkl'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" json\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" joblib\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" azureml"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("core"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("model "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Model\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Called when the service is loaded")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("init")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("global")]),t._v(" model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" explainer\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# load the model")]),t._v("\n    model_path "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_model_path"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'loan_model'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    model "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" joblib"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("load"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("model_path"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# load the explainer")]),t._v("\n    explainer_path "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_model_path"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'loan_explainer'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    explainer "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" joblib"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("load"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("explainer_path"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Called when a request is received")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("run")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("raw_data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Get the input data")]),t._v("\n    data "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" np"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("array"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("json"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("loads"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("raw_data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'data'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Get a prediction from the model")]),t._v("\n    predictions "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("predict"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Get explanations")]),t._v("\n    importance_values "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" explainer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("explain"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Return the predictions and explanations as JSON")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"predictions"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("predictions"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tolist"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"importance"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("importance_values"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("service "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("deploy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ws"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'loan-svc'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" explainer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" inf_config"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dep_config"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])])}),[],!1,null,null,null);a.default=e.exports}}]);