(window.webpackJsonp=window.webpackJsonp||[]).push([[40],{398:function(t,s,a){"use strict";a.r(s);var n=a(42),e=Object(n.a)({},(function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"azure-dp-100-module-3"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#azure-dp-100-module-3"}},[t._v("#")]),t._v(" Azure DP-100 Module 3")]),t._v(" "),a("h2",{attrs:{id:"running-experiments-and-training-models"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#running-experiments-and-training-models"}},[t._v("#")]),t._v(" Running Experiments and Training Models")]),t._v(" "),a("p",[t._v("In AMZL, an experiment is a named process (running a file or a script) that generates outputs.")]),t._v(" "),a("h3",{attrs:{id:"the-run-context"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#the-run-context"}},[t._v("#")]),t._v(" The "),a("code",[t._v("Run Context")])]),t._v(" "),a("p",[t._v("The "),a("code",[t._v("run context")]),t._v(" is used to start/end an experiment. Once completed results are visibile in AML Studio")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("experiment "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Experiment"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("worskpace "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ws"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" name "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'my_exp'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nrun "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" experiment"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("start_logging"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n\nrun"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("complete"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("h3",{attrs:{id:"logging-metrics-outputs"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#logging-metrics-outputs"}},[t._v("#")]),t._v(" Logging Metrics & Outputs")]),t._v(" "),a("p",[t._v("The "),a("code",[t._v("Run")]),t._v(" object provides logging functions:")]),t._v(" "),a("ul",[a("li",[a("code",[t._v("log")]),t._v(": Single named value")]),t._v(" "),a("li",[a("code",[t._v("log_list")]),t._v(": Named list of values")]),t._v(" "),a("li",[a("code",[t._v("log_row")]),t._v(": Row with multiple columns")]),t._v(" "),a("li",[a("code",[t._v("log_table")]),t._v(": Dictionary as a table")]),t._v(" "),a("li",[a("code",[t._v("log_image")]),t._v(": Log Image or plot")])]),t._v(" "),a("p",[a("strong",[t._v("Note")])]),t._v(" "),a("p",[a("code",[t._v("ML Flow")]),t._v(" can be used in conjuction with AML, see "),a("a",{attrs:{href:"https://docs.microsoft.com/en-us/azure/machine-learning/how-to-use-mlflow",target:"_blank",rel:"noopener noreferrer"}},[t._v("docs"),a("OutboundLink")],1)]),t._v(" "),a("h3",{attrs:{id:"retrieving-logged-metrics"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#retrieving-logged-metrics"}},[t._v("#")]),t._v(" Retrieving Logged Metrics")]),t._v(" "),a("p",[t._v("The "),a("code",[t._v("RunDetails")]),t._v(" object provides widget capability in a notebook to view metrics")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" azureml"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("widgets "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" RunDetails\n\nRunDetails"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("run"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Metrics can also be retrieved using the run object")]),t._v("\nmetrics "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" run"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_metrics"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("h3",{attrs:{id:"output"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#output"}},[t._v("#")]),t._v(" Output")]),t._v(" "),a("p",[t._v("Output files are saved in the "),a("code",[t._v("outputs")]),t._v(" folder and it can be done by using the "),a("code",[t._v("run")]),t._v(" object.")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("run"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("upload_file"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'outputs/sample.csv'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" path_or_stream"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'./sample.csv'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# To get the list of outputs")]),t._v("\nfiles "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" run"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_file_names"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("h3",{attrs:{id:"running-a-script-as-an-experiment"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#running-a-script-as-an-experiment"}},[t._v("#")]),t._v(" Running a Script as an Experiment")]),t._v(" "),a("p",[t._v("When running from a script, to access the experiment run context, the "),a("strong",[t._v("script")]),t._v(" needs to have the "),a("code",[t._v("azureml.core.Run")]),t._v(" class imported and call the "),a("code",[t._v("get_context")]),t._v(" method.")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" azureml"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("core "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Run\nrun "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Run"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_context"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\nrun"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("complete"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("h3",{attrs:{id:"running-an-experiment-script"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#running-an-experiment-script"}},[t._v("#")]),t._v(" Running an Experiment Script")]),t._v(" "),a("p",[t._v("A  "),a("code",[t._v("script configuration")]),t._v(" is required to define the script to be run and the environment in which it'll run, this is achieved using the "),a("code",[t._v("ScriptRunConfig")]),t._v(" object.")]),t._v(" "),a("p",[t._v("To associate a script with a RunConfig, you must use a ScriptRunConfig object.")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" azureml"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("core "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Experiment"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ScriptRunConfig\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Create a script config")]),t._v("\nscript_config "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ScriptRunConfig"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("source_directory"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("experiment_folder"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                                script"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'experiment.py'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# submit the experiment")]),t._v("\nexperiment "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Experiment"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("workspace "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ws"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" name "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'my-experiment'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nrun "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" experiment"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("submit"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("config"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("script_config"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nrun"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("wait_for_completion"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("show_output"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[a("strong",[t._v("Note")])]),t._v(" "),a("p",[t._v("If your script depends on packages that are not included in the default environment, you must associate the "),a("code",[t._v("ScriptRunConfig")]),t._v(" with an Environment object that makes use of a "),a("code",[t._v("CondaDependencies")]),t._v(" object to specify the Python packages required.")]),t._v(" "),a("h2",{attrs:{id:"training-and-registering-models"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#training-and-registering-models"}},[t._v("#")]),t._v(" Training and Registering Models")]),t._v(" "),a("h3",{attrs:{id:"estimators"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#estimators"}},[t._v("#")]),t._v(" Estimators")]),t._v(" "),a("p",[t._v("AML provides an "),a("code",[t._v("Estimator")]),t._v(" class that combines a "),a("code",[t._v("run configuration")]),t._v(" and a "),a("code",[t._v("script configuration")]),t._v(" in a single object to make it easy to run Scripts (removes the need to manage packages).")]),t._v(" "),a("p",[t._v("Link to "),a("a",{attrs:{href:"https://docs.microsoft.com/en-us/azure/machine-learning/how-to-set-up-training-targets",target:"_blank",rel:"noopener noreferrer"}},[t._v("docs"),a("OutboundLink")],1)]),t._v(" "),a("h3",{attrs:{id:"writing-a-script-to-train-a-model"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#writing-a-script-to-train-a-model"}},[t._v("#")]),t._v(" Writing a Script to train a Model")]),t._v(" "),a("p",[t._v("The script should save the trained model in the outputs folder.")]),t._v(" "),a("p",[t._v("Example training script below:")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" azureml"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("core "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Run\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pandas "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" pd\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" numpy "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" np\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" joblib\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" sklearn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("model_selection "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" train_test_split\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" sklearn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("linear_model "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" LogisticRegression\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Get the experiment run context")]),t._v("\nrun "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Run"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_context"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n\nmodel "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" LogisticRegression"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("C"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("reg"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" solver"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"liblinear"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fit"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Save the trained model")]),t._v("\nos"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("makedirs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'outputs'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" exist_ok"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\njoblib"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dump"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("value"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" filename"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'outputs/model.pkl'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nrun"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("complete"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[t._v("Then using the estimator, you can run the script quite easily and define the "),a("code",[t._v("run configuration")]),t._v(".")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" azureml"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("estimator "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Estimator\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" azureml"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("core "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Experiment\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Create an estimator")]),t._v("\nestimator "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Estimator"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("source_directory"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'experiment_folder'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                      entry_script"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'training_script.py'")]),t._v("\n                      compute_target"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'local'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                      conda_packages"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'scikit-learn'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n                      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Create and run an experiment")]),t._v("\nexperiment "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Experiment"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("workspace "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ws"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" name "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'training_experiment'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nrun "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" experiment"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("submit"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("config"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("estimator"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[a("strong",[t._v("Notes")])]),t._v(" "),a("p",[t._v("You can use the framework specific estimators and it will have the required conda packages pre-installed.")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" azureml"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sklearn "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" SKLearn\n\nestimator "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" SKLearn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("source_directory"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'experiment_folder'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                    entry_script"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'training_script.py'")]),t._v("\n                    compute_target"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'local'")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("h3",{attrs:{id:"script-parameters"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#script-parameters"}},[t._v("#")]),t._v(" Script Parameters")]),t._v(" "),a("p",[t._v("The library "),a("code",[t._v("arparse")]),t._v(" has to be used to read the arguments passed to the script.")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" azureml"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("core "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Run\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" argparse\n\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Get the experiment run context")]),t._v("\nrun "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Run"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_context"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Set regularization hyperparameter")]),t._v("\nparser "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" argparse"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ArgumentParser"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nparser"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_argument"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'--reg_rate'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("type")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("float")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dest"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'reg'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" default"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.01")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nargs "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" parser"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parse_args"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nreg "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" args"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reg\n\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Train a logistic regression model")]),t._v("\nmodel "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" LogisticRegression"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("C"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("reg"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" solver"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"liblinear"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fit"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Save the trained model")]),t._v("\nos"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("makedirs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'outputs'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" exist_ok"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\njoblib"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dump"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("value"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" filename"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'outputs/model.pkl'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nrun"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("complete"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[t._v("The estimator can also receive the parameters by using the "),a("code",[t._v("script_params")]),t._v(" value.")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Create an estimator")]),t._v("\nestimator "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" SKLearn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("source_directory"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'experiment_folder'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                    entry_script"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'training_script.py'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                    script_params "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'--reg_rate'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                    compute_target"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'local'")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("h3",{attrs:{id:"registering-a-trained-model"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#registering-a-trained-model"}},[t._v("#")]),t._v(" Registering a Trained Model")]),t._v(" "),a("p",[t._v("The "),a("code",[t._v("Run")]),t._v(" object can be used to retrieve outputs including models. The "),a("code",[t._v("get_file_names")]),t._v(" lists all the files generated and you can use the "),a("code",[t._v("download_file")]),t._v("/"),a("code",[t._v("download_files")]),t._v(" to download the output files in the local file system.")]),t._v(" "),a("h4",{attrs:{id:"registering-a-model"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#registering-a-model"}},[t._v("#")]),t._v(" Registering a Model")]),t._v(" "),a("p",[t._v("AML provides the ability to register and keep track of models and their versions and use this for inferencing. It is done using the "),a("code",[t._v("register")]),t._v(" method of the "),a("code",[t._v("Model")]),t._v(" object.")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" azureml"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("core "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Model\n\nmodel "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("register"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("workspace"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("ws"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                       model_name"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'classification_model'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                       model_path"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'model.pkl'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# local path")]),t._v("\n                       description"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'A classification model'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                       tags"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'dept'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'sales'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                       model_framework"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("Model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Framework"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("SCIKITLEARN"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                       model_framework_version"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'0.20.3'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# To view the models")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" model "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" Model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("list")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ws"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Get model name and auto-generated version")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'version:'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("version"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])])}),[],!1,null,null,null);s.default=e.exports}}]);