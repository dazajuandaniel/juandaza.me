(window.webpackJsonp=window.webpackJsonp||[]).push([[46],{321:function(t,a,s){"use strict";s.r(a);var n=s(14),e=Object(n.a)({},(function(){var t=this,a=t._self._c;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"azure-dp-100-module-8"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#azure-dp-100-module-8"}},[t._v("#")]),t._v(" Azure DP-100 Module 8")]),t._v(" "),a("h2",{attrs:{id:"hyperparameter-tuning"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#hyperparameter-tuning"}},[t._v("#")]),t._v(" Hyperparameter Tuning")]),t._v(" "),a("p",[t._v("AML enables Hyperparameter tunning with the "),a("code",[t._v("hyperdrive")]),t._v(" run that initiates a child run for each hyperparameter combination.")]),t._v(" "),a("h3",{attrs:{id:"search-space"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#search-space"}},[t._v("#")]),t._v(" Search Space")]),t._v(" "),a("p",[t._v("The possible space types are:")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("Discrete Hyperparameters")]),t._v(" "),a("ul",[a("li",[t._v("Uses "),a("code",[t._v("choice")]),t._v(", e.g. "),a("code",[t._v("choice([10,20,30])")]),t._v(" or "),a("code",[t._v("choice(range(50))")])]),t._v(" "),a("li",[t._v("From a discrete distrbution ("),a("code",[t._v("qnormal")]),t._v(","),a("code",[t._v("quniform")]),t._v(","),a("code",[t._v("qlognormal")]),t._v(","),a("code",[t._v("qloguniform")]),t._v(")")])])]),t._v(" "),a("li",[a("p",[t._v("Continous Hyperparameters")]),t._v(" "),a("ul",[a("li",[t._v("From a continous distribution ("),a("code",[t._v("normal")]),t._v(","),a("code",[t._v("uniform")]),t._v(","),a("code",[t._v("lognormal")]),t._v(","),a("code",[t._v("loguniform")]),t._v(")")])])])]),t._v(" "),a("p",[t._v("To define a search space, create a "),a("code",[t._v("dictionary")]),t._v(" with the appropiate values")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" azureml"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("hyperdrive "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" choice"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" normal\n\nparam_space "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                 "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'--batch_size'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" choice"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("16")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("32")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("64")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                 "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'--learning_rate'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" normal"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n              "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),a("h3",{attrs:{id:"hyperparameter-sampling"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#hyperparameter-sampling"}},[t._v("#")]),t._v(" Hyperparameter Sampling")]),t._v(" "),a("p",[t._v("The values used in the Hyperparameter tuning depend on the sampling method:")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("Grid Sampling")]),t._v(" "),a("p",[t._v("Can only be employed whan all Hyperparameters are discrete (tries every combination possible)")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" azureml"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("hyperdrive "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" GridParameterSampling"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" choice\n\nparam_space "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'--batch_size'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" choice"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("16")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("32")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("64")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'--learning_rate'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" choice"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.01")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\nparam_sampling "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" GridParameterSampling"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("param_space"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])]),t._v(" "),a("li",[a("p",[t._v("Random Sampling")]),t._v(" "),a("p",[t._v("Randomly selects a value from the hyperparameters")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" azureml"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("hyperdrive "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" RandomParameterSampling"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" choice"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" normal\n\nparam_space "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'--batch_size'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" choice"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("16")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("32")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("64")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'--learning_rate'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" normal"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\nparam_sampling "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" RandomParameterSampling"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("param_space"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])]),t._v(" "),a("li",[a("p",[t._v("Bayesian Sampling")]),t._v(" "),a("p",[t._v("Chooses hyperparameter values based on the Bayesian optimization algorithm, which tries to select parameter combinations that will result in improved performance from the previous selection")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" azureml"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("hyperdrive "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" BayesianParameterSampling"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" choice"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" uniform\n\nparam_space "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'--batch_size'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" choice"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("16")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("32")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("64")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'--learning_rate'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" uniform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\nparam_sampling "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" BayesianParameterSampling"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("param_space"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[a("strong",[t._v("Note:")]),t._v(" You can only use Bayesian sampling with choice, uniform, and quniform parameter expressions, and you can't combine it with an early-termination policy.")])])]),t._v(" "),a("h3",{attrs:{id:"early-termination-policy"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#early-termination-policy"}},[t._v("#")]),t._v(" Early Termination Policy")]),t._v(" "),a("p",[t._v("Prevents long runs by allowing the definition of policies to terminate early based on performance or other aspects such as based on the number of runs.")]),t._v(" "),a("ul",[a("li",[t._v("Bandit Policy: Stops a run if the target performance metric underperforms the best run so far by a specified margin."),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" azureml"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("hyperdrive "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" BanditPolicy\n\nearly_termination_policy "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" BanditPolicy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("slack_amount "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                                        evaluation_interval"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                                        delay_evaluation"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])]),t._v(" "),a("li",[t._v("Median Stopping Policy: Abandons runs where the target performance metric is worse than the median of the running averages for all runs."),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" azureml"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("hyperdrive "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" MedianStoppingPolicy\n\nearly_termination_policy "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" MedianStoppingPolicy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("evaluation_interval"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                                                delay_evaluation"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])]),t._v(" "),a("li",[t._v("Truncation Selection Policy: Cancels the lowest performing X% of runs at each evaluation interval based on the truncation_percentage value you specify for X."),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" azureml"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("hyperdrive "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" TruncationSelectionPolicy\n\nearly_termination_policy "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" TruncationSelectionPolicy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("truncation_percentage"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                                                    evaluation_interval"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                                                    delay_evaluation"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])])]),t._v(" "),a("h3",{attrs:{id:"using-hyperdrive"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#using-hyperdrive"}},[t._v("#")]),t._v(" Using Hyperdrive")]),t._v(" "),a("p",[t._v("Parameters are tunned using the "),a("code",[t._v("Hyperdrive")]),t._v(" experiment object. The script "),a("strong",[t._v("MUST")]),t._v(" have:")]),t._v(" "),a("ul",[a("li",[t._v("An argument for each hyperparameter")]),t._v(" "),a("li",[t._v("Log the target performance metric.")])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" argparse\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" joblib\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" azureml"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("core "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Run\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pandas "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" pd\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" numpy "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" np\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" sklearn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("model_selection "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" train_test_split\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" sklearn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("linear_model "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" LogisticRegression\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Get regularization hyperparameter")]),t._v("\nparser "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" argparse"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ArgumentParser"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nparser"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_argument"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'--regularization'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("type")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("float")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dest"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'reg_rate'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" default"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.01")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nargs "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" parser"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parse_args"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nreg "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" args"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reg_rate\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Get the experiment run context")]),t._v("\nrun "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Run"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_context"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# load the training dataset")]),t._v("\ndata "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" run"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("input_datasets"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'training_data'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("to_pandas_dataframe"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Separate features and labels, and split for training/validatiom")]),t._v("\nX "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'feature1'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'feature2'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'feature3'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'feature4'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("values\ny "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'label'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("values\nX_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" X_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y_test "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" train_test_split"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" test_size"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.30")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Train a logistic regression model with the reg hyperparameter")]),t._v("\nmodel "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" LogisticRegression"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("C"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("reg"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" solver"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"liblinear"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fit"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# calculate and log accuracy")]),t._v("\ny_hat "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("predict"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nacc "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" np"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("average"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("y_hat "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" y_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nrun"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("log"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Accuracy'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" np"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("float")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("acc"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Save the trained model")]),t._v("\nos"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("makedirs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'outputs'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" exist_ok"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\njoblib"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dump"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("value"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" filename"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'outputs/model.pkl'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nrun"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("complete"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[t._v("Once the script is ready, you have to use a "),a("code",[t._v("HyperDriveConfig")]),t._v(".")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" azureml"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("core "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Experiment\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" azureml"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("hyperdrive "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" HyperDriveConfig"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" PrimaryMetricGoal\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Assumes ws, sklearn_estimator and param_sampling are already defined")]),t._v("\n\nhyperdrive "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" HyperDriveConfig"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("estimator"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("sklearn_estimator"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                              hyperparameter_sampling"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("param_sampling"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                              policy"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                              primary_metric_name"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Accuracy'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                              primary_metric_goal"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("PrimaryMetricGoal"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("MAXIMIZE"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                              max_total_runs"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                              max_concurrent_runs"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nexperiment "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Experiment"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("workspace "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ws"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" name "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'hyperdrive_training'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nhyperdrive_run "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" experiment"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("submit"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("config"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("hyperdrive"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("h3",{attrs:{id:"monitor-the-hyperdrive-run"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#monitor-the-hyperdrive-run"}},[t._v("#")]),t._v(" Monitor the Hyperdrive Run")]),t._v(" "),a("p",[t._v("Use the "),a("code",[t._v("RunDetails")]),t._v(" widget. The experiment will intiate a run child for each hyperparameter combination tried.")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Get logs for each run")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" child_run "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" run"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_children"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("child_run"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("id")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" child_run"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_metrics"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# List all runs")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" child_run "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" hyperdrive_"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_children_sorted_by_primary_metric"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("child_run"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Get best performing run")]),t._v("\nbest_run "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" hyperdrive_run"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_best_run_by_primary_metric"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("h2",{attrs:{id:"automl"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#automl"}},[t._v("#")]),t._v(" AutoML")]),t._v(" "),a("p",[t._v("Available in Studio for Enterprise. Avaialbe in Free for both Enterprise and Basic.")]),t._v(" "),a("p",[t._v("It can be used for the following types of tasks.")]),t._v(" "),a("ul",[a("li",[t._v("Classification\n"),a("ul",[a("li",[t._v("Logistic Regression")]),t._v(" "),a("li",[t._v("GBM")]),t._v(" "),a("li",[t._v("Decision Tree")]),t._v(" "),a("li",[t._v("Random Forest")]),t._v(" "),a("li",[t._v("Naive Bayes")]),t._v(" "),a("li",[t._v("SVM")]),t._v(" "),a("li",[t._v("XGBoost")]),t._v(" "),a("li",[t._v("DNN and more")])])]),t._v(" "),a("li",[t._v("Regression\n"),a("ul",[a("li",[t._v("Linear Regression")]),t._v(" "),a("li",[t._v("GBM")]),t._v(" "),a("li",[t._v("Decision Tree")]),t._v(" "),a("li",[t._v("Random Forest")]),t._v(" "),a("li",[t._v("Elastic Net")]),t._v(" "),a("li",[t._v("LARS Lasso")]),t._v(" "),a("li",[t._v("XGBoost")])])]),t._v(" "),a("li",[t._v("Time Series Forecasting\n"),a("ul",[a("li",[t._v("Etc")])])])]),t._v(" "),a("p",[t._v("You can choose which algorithms to run/avoid.")]),t._v(" "),a("p",[a("a",{attrs:{href:"https://docs.microsoft.com/en-us/azure/machine-learning/concept-automated-ml",target:"_blank",rel:"noopener noreferrer"}},[t._v("Full list here"),a("OutboundLink")],1)]),t._v(" "),a("h3",{attrs:{id:"preprocessing-featurisation"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#preprocessing-featurisation"}},[t._v("#")]),t._v(" Preprocessing & Featurisation")]),t._v(" "),a("ul",[a("li",[t._v("Scaling and Normalisation")]),t._v(" "),a("li",[t._v("Missing value imputing")]),t._v(" "),a("li",[t._v("Categorical encoding")]),t._v(" "),a("li",[t._v("Dropping high cardinality features")]),t._v(" "),a("li",[t._v("Feature Engineering (e.g. deriving date parts)")])]),t._v(" "),a("p",[a("a",{attrs:{href:"https://docs.microsoft.com/en-us/azure/machine-learning/concept-automated-ml#preprocessing",target:"_blank",rel:"noopener noreferrer"}},[t._v("More details here"),a("OutboundLink")],1)]),t._v(" "),a("h3",{attrs:{id:"running-an-experiment"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#running-an-experiment"}},[t._v("#")]),t._v(" Running an experiment")]),t._v(" "),a("p",[t._v("Everything is setup using the "),a("code",[t._v("AutoMLConfig")]),t._v(" class")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" azureml"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("automl "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" AutoMLConfig\n\nautoml_run_config "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" RunConfiguration"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("framework"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'python'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nautoml_config "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" AutoMLConfig"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Automated ML Experiment'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                             task"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'classification'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                             primary_metric "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'AUC_weighted'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                             compute_target"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("aml_compute"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                             training_data "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" train_dataset"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                             validation_data "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" test_dataset"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                             label_column_name"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Label'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                             featurization"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'auto'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                             iterations"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                             max_concurrent_iterations"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[t._v("To get the list of primary metrics supported, use the "),a("code",[t._v("get_primary_metrics")]),t._v(" function")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" azureml"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("automl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("utilities "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" get_primary_metrics\n\nget_primary_metrics"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'classification'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[t._v("Submission is done like any other experiment")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" azureml"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("core"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("experiment "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Experiment\n\nautoml_experiment "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Experiment"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ws"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'automl_experiment'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nautoml_run "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" automl_experiment"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("submit"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("automl_config"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("h3",{attrs:{id:"monitor-the-automl-run"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#monitor-the-automl-run"}},[t._v("#")]),t._v(" Monitor the Automl Run")]),t._v(" "),a("p",[t._v("Use the "),a("code",[t._v("RunDetails")]),t._v(" widget. The experiment will intiate a run child for each hyperparameter combination tried.")]),t._v(" "),a("p",[t._v("The get_output method of an automated machine learning run returns the best mode and the child run that trained it.")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("best_run"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" fitted_model "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" automl_run"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_output"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nbest_run_metrics "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" best_run"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_metrics"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" metric_name "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" best_run_metrics"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    metric "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" best_run_metrics"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("metric_name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("metric_name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" metric"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Exploer the Preprocessing steps")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" step_ "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" fitted_model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("named_steps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("step"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])])}),[],!1,null,null,null);a.default=e.exports}}]);