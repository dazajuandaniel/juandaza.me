(window.webpackJsonp=window.webpackJsonp||[]).push([[45],{320:function(t,s,a){"use strict";a.r(s);var n=a(14),e=Object(n.a)({},(function(){var t=this,s=t._self._c;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h1",{attrs:{id:"azure-dp-100-module-7"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#azure-dp-100-module-7"}},[t._v("#")]),t._v(" Azure DP-100 Module 7")]),t._v(" "),s("h2",{attrs:{id:"real-time-inferencing"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#real-time-inferencing"}},[t._v("#")]),t._v(" Real-time Inferencing")]),t._v(" "),s("p",[t._v("AML allows you to deploy the inferencing service in a hosted platform such as AKS.")]),t._v(" "),s("h3",{attrs:{id:"deploying-a-service"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#deploying-a-service"}},[t._v("#")]),t._v(" Deploying a Service")]),t._v(" "),s("p",[t._v("AML uses "),s("code",[t._v("containers")]),t._v(" as a deployment mechanism, packaging the model and code to be able to be deployed into a container in whatever target (local, ACI, AKS, Azure Function, etc).")]),t._v(" "),s("p",[s("strong",[t._v("General Steps to deploy")])]),t._v(" "),s("ol",[s("li",[s("p",[t._v("Register a trained model in the workspace")])]),t._v(" "),s("li",[s("p",[t._v("Define an Inference Configuration")]),t._v(" "),s("ul",[s("li",[t._v("The model consists of a "),s("em",[t._v("script to load the model")]),t._v(" and "),s("em",[t._v("an enviroment the script will run")])])])]),t._v(" "),s("li",[s("p",[t._v("Create an entry Script")]),t._v(" "),s("ul",[s("li",[s("p",[t._v("Script must have "),s("code",[t._v("init()")]),t._v(" and "),s("code",[t._v("run(raw_data)")]),t._v(" function")]),t._v(" "),s("ul",[s("li",[t._v("init(): Called when the services is initialised (e.g. load the model)")]),t._v(" "),s("li",[t._v("run(raw_data): Called when new data is submitted (e.g. generating predictions)")])]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" json\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" joblib\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" numpy "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" np\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" azureml"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("core"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("model "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Model\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Called when the service is loaded")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("init")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("global")]),t._v(" model\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Get the path to the registered model file and load it")]),t._v("\n    model_path "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_model_path"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'classification_model'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    model "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" joblib"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("load"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("model_path"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Called when a request is received")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("run")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("raw_data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Get the input data as a numpy array")]),t._v("\n    data "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" np"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("array"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("json"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("loads"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("raw_data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'data'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Get a prediction from the model")]),t._v("\n    predictions "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("predict"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Return the predictions as any JSON serializable format")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" predictions"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tolist"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])])])]),t._v(" "),s("li",[s("p",[t._v("Create the environment:")]),t._v(" "),s("ul",[s("li",[t._v("You can configure using Conda configuration file using the "),s("code",[t._v("CondaDependencies")]),t._v(" class.")])]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" azureml"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("core"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("conda_dependencies "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" CondaDependencies\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Add the dependencies for your model")]),t._v("\nmyenv "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" CondaDependencies"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nmyenv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_conda_package"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"scikit-learn"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Save the environment config as a .yml file")]),t._v("\nenv_file "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'service_files/env.yml'")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("with")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("open")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("env_file"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"w"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" f"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    f"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("write"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("myenv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("serialize_to_string"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Saved dependency info in"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" env_file"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])]),t._v(" "),s("li",[s("p",[t._v("Combine Script + Environment")]),t._v(" "),s("ul",[s("li",[t._v("Combine it using the "),s("code",[t._v("InferenceConfig")])])]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" azureml"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("core"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("model "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" InferenceConfig\n\nclassifier_inference_config "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" InferenceConfig"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("runtime"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"python"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                                            source_directory "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'service_files'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                                            entry_script"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"score.py"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                                            conda_file"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"env.yml"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])]),t._v(" "),s("li",[s("p",[t._v("Define a deployment Configuration")]),t._v(" "),s("ul",[s("li",[t._v("Configure the compute to which the service will be deployed.")])]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" azureml"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("core"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("compute "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" ComputeTarget"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" AksCompute\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" azureml"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("core"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("webservice "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" AksWebservice\n\n\ncluster_name "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'aks-cluster'")]),t._v("\ncompute_config "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" AksCompute"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("provisioning_configuration"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("location"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'eastus'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nproduction_cluster "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ComputeTarget"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("create"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ws"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" cluster_name"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" compute_config"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nproduction_cluster"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("wait_for_completion"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("show_output"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nclassifier_deploy_config "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" AksWebservice"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("deploy_configuration"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cpu_cores "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                                                            memory_gb "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])]),t._v(" "),s("li",[s("p",[t._v("Deploy the model")]),t._v(" "),s("ul",[s("li",[t._v("Call "),s("code",[t._v("deploy")]),t._v(" method of the "),s("code",[t._v("Model")]),t._v(" class.")])])])]),t._v(" "),s("h4",{attrs:{id:"consuming-an-inferencing-service"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#consuming-an-inferencing-service"}},[t._v("#")]),t._v(" Consuming an Inferencing Service")]),t._v(" "),s("p",[t._v("To consume you can use the endpoint to make calls. For authentication you need the either the "),s("code",[t._v("key")]),t._v(" or "),s("code",[t._v("token")]),t._v(" (JWT).")]),t._v(" "),s("p",[s("strong",[t._v("Notes:")])]),t._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",[s("code",[t._v("* Authentication is disabled by default for ACI services\n* Autehntication is set to key-based for AKS\n* For token-based authentication, your client application needs to use service-principal authentication to verify its identity through Azure Active Directory (Azure AD) and call the get_token method of the service to retrieve a time-limited token.\n")])])]),s("h4",{attrs:{id:"troubleshooting"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#troubleshooting"}},[t._v("#")]),t._v(" Troubleshooting")]),t._v(" "),s("ol",[s("li",[t._v("Check the state by using the "),s("code",[t._v("state")]),t._v(" method (use a service specific method such as "),s("code",[t._v("AksWebservice")]),t._v(" instead of "),s("code",[t._v("WebService")]),t._v(")."),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" azureml"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("core"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("webservice "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" AksWebservice\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Get the deployed service")]),t._v("\nservice "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" AciWebservice"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'classifier-service'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" workspace"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("ws"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Check its state")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("service"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("state"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])]),t._v(" "),s("li",[t._v("Review Service Logs"),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("service"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_logs"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])]),t._v(" "),s("li",[t._v("Deploy to local container for easy diagnosis")])]),t._v(" "),s("h3",{attrs:{id:"batch-inferencing"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#batch-inferencing"}},[t._v("#")]),t._v(" Batch Inferencing")]),t._v(" "),s("p",[t._v("Apply predictive models to batch operations "),s("code",[t._v("asynchronously")]),t._v(" and write results to a DB/file.")]),t._v(" "),s("h4",{attrs:{id:"create-batch-pipeline"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#create-batch-pipeline"}},[t._v("#")]),t._v(" Create Batch Pipeline")]),t._v(" "),s("p",[s("strong",[t._v("General Steps to deploy")])]),t._v(" "),s("ol",[s("li",[s("p",[t._v("Register the model (similar to Real Time inferencing)")])]),t._v(" "),s("li",[s("p",[t._v("Create a scoring script:")]),t._v(" "),s("ul",[s("li",[s("p",[t._v("Script must have "),s("code",[t._v("init()")]),t._v(" and "),s("code",[t._v("run(mini_batch)")]),t._v(" function")]),t._v(" "),s("ul",[s("li",[t._v("init(): Called when the pipeline is initialised (e.g. load the model)")]),t._v(" "),s("li",[t._v("run(raw_data): Called for each batch (e.g. generating predictions)")])]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" json\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" joblib\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" numpy "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" np\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" azureml"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("core"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("model "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Model\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Called when the service is loaded")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("init")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("global")]),t._v(" model\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Get the path to the registered model file and load it")]),t._v("\n    model_path "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_model_path"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'classification_model'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    model "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" joblib"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("load"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("model_path"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Called when a request is received")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("run")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("mini_batch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# process each file in the batch")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" f "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" mini_batch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Read comma-delimited data into an array")]),t._v("\n        data "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" np"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("genfromtxt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("f"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" delimiter"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("','")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Reshape into a 2-dimensional array for model input")]),t._v("\n        prediction "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" model"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("predict"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reshape"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Append prediction to results")]),t._v("\n        resultList"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("append"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"{}: {}"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("format")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("os"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("path"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("basename"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("f"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" prediction"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" resultList\n")])])])])])]),t._v(" "),s("li",[s("p",[t._v("Create a Pipeline with a "),s("code",[t._v("ParallelRunStep")])]),t._v(" "),s("ul",[s("li",[t._v("AML provides a step to perform parallel batch inferencing ("),s("code",[t._v("ParallelRunStep")]),t._v("). Output can be written to a "),s("code",[t._v("PipelineData")]),t._v(" reference. Also, you can set the "),s("code",[t._v("output_action = append_row")]),t._v(" setting to ensure that all instances of the step that are run in parallel, collate their results to a single file")])]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" azureml"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("pipeline"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("steps "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" ParallelRunConfig"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ParallelRunStep\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" azureml"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("pipeline"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("core "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" PipelineData\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" azureml"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("pipeline"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("core "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Pipeline\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Get the batch dataset for input")]),t._v("\nbatch_data_set "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ws"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("datasets"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'batch-data'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Set the output location")]),t._v("\ndefault_ds "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ws"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_default_datastore"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\noutput_dir "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" PipelineData"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'inferences'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                        datastore"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("default_ds"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                        output_path_on_compute"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'results'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Define the parallel run step step configuration")]),t._v("\nparallel_run_config "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ParallelRunConfig"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    source_directory"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'batch_scripts'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    entry_script"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"batch_scoring_script.py"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    mini_batch_size"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"5"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    error_threshold"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    output_action"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"append_row"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    environment"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("batch_env"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    compute_target"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("aml_cluster"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    node_count"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Create the parallel run step")]),t._v("\nparallelrun_step "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ParallelRunStep"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    name"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'batch-score'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    parallel_run_config"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("parallel_run_config"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    inputs"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("batch_data_set"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("as_named_input"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'batch_data'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    output"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("output_dir"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    arguments"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    allow_reuse"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Create the pipeline")]),t._v("\npipeline "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Pipeline"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("workspace"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("ws"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" steps"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("parallelrun_step"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])]),t._v(" "),s("li",[s("p",[t._v("Run the pipeline and retrieve Step Output")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" azureml"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("core "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Experiment\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Run the pipeline as an experiment")]),t._v("\npipeline_run "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Experiment"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ws"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'batch_prediction_pipeline'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("submit"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("pipeline"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npipeline_run"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("wait_for_completion"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("show_output"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Get the outputs from the first (and only) step")]),t._v("\nprediction_run "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("next")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("pipeline_run"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_children"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nprediction_output "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" prediction_run"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_output_data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'inferences'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nprediction_output"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("download"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("local_path"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'results'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Find the parallel_run_step.txt file")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" root"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dirs"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" files "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" os"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("walk"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'results'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("file")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" files"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("file")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("endswith"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'parallel_run_step.txt'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            result_file "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" os"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("path"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("join"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("root"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("file")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Load and display the results")]),t._v("\ndf "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pd"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_csv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("result_file"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" delimiter"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('":"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" header"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ndf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("columns "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"File"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Prediction"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("df"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])])]),t._v(" "),s("h4",{attrs:{id:"publishing-batch-service"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#publishing-batch-service"}},[t._v("#")]),t._v(" Publishing Batch Service")]),t._v(" "),s("p",[t._v("Same as Real Time Publishing.")]),t._v(" "),s("ol",[s("li",[t._v("Publish as a Rest service")]),t._v(" "),s("li",[t._v("Use the service to intiate the pipeline on demand")]),t._v(" "),s("li",[t._v("You can Schedule the pipeline as well using the "),s("code",[t._v("ScheduleRecurrence")]),t._v(" and "),s("code",[t._v("Schedule")]),t._v(" object.")])])])}),[],!1,null,null,null);s.default=e.exports}}]);