(window.webpackJsonp=window.webpackJsonp||[]).push([[54],{412:function(s,t,a){"use strict";a.r(t);var e=a(42),r=Object(e.a)({},(function(){var s=this,t=s.$createElement,a=s._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[a("h1",{attrs:{id:"etl-using-sql-on-databricks"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#etl-using-sql-on-databricks"}},[s._v("#")]),s._v(" ETL using SQL on Databricks")]),s._v(" "),a("p",[s._v("Brief overview of using SQL to Extract, Load, & Transform data in Databricks. Topics to discuss:")]),s._v(" "),a("ul",[a("li",[s._v("Extracting data directly & Using options for external sources")]),s._v(" "),a("li",[s._v("Delta Tables")]),s._v(" "),a("li",[s._v("SQL Transformations")]),s._v(" "),a("li",[s._v("UDFs & Control Flows")])]),s._v(" "),a("h2",{attrs:{id:"extracting-files-directly"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#extracting-files-directly"}},[s._v("#")]),s._v(" Extracting Files Directly")]),s._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("SELECT")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("FROM")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v("file_format"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("path_to_file"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("--JSON")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("SELECT")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("FROM")]),s._v(" json"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("my"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("path"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("here"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("--CSV")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("SELECT")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("FROM")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("text")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("my"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("path"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("here"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v(" \n")])])]),a("p",[s._v("Assuming all files in the path_to_file have the same schema, only folder is required, not file itself.")]),s._v(" "),a("p",[s._v("This works best for self-describing formats ("),a("code",[s._v("json")]),s._v(", "),a("code",[s._v("parquet")]),s._v(", "),a("code",[s._v("delta")]),s._v(") not really for formats such as "),a("code",[s._v("csv")]),s._v(".")]),s._v(" "),a("p",[s._v("For "),a("code",[s._v("csv")]),s._v(", the best is to have a schema declaration. This can be done by using External Data Sources.")]),s._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("CREATE")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("TEMPORARY")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("TABLE")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v("table_name"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("USING")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v("format"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" OPTIONS "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v("options"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" \n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("--CSV")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("CREATE")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("TEMPORARY")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("TABLE")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v("table_name"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("schema")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("USING")]),s._v(" CSV OPTIONS "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n    header "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'true'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("delimiter")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("','")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nLOCATION "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'my/path/here'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" \n")])])]),a("p",[a("strong",[s._v("JDBC")]),s._v(" connections can also be used.")]),s._v(" "),a("p",[a("strong",[s._v("Limits of External Data Sources")])]),s._v(" "),a("ul",[a("li",[s._v("when defining tables against external sources we cannot guarantee performance guarantees associated with "),a("code",[s._v("Delta")]),s._v(" i.e. latest version, etc")]),s._v(" "),a("li",[s._v("We can manually refresh by running"),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[s._v("REFRESH "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("TABLE")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v("table_name"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v("\n")])])])])]),s._v(" "),a("h2",{attrs:{id:"delta-tables"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#delta-tables"}},[s._v("#")]),s._v(" Delta Tables")]),s._v(" "),a("p",[s._v("CTAS (Create Table as Select)")]),s._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("CREATE")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("OR")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("REPLACE")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("TABLE")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v("tb_name"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("AS")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("SELECT")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("FROM")]),s._v(" parquet"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("file")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("path"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("DESCRIBE")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("EXTENDED")]),s._v(" sales\n")])])]),a("p",[s._v("Notes on CTAS:")]),s._v(" "),a("ul",[a("li",[s._v("Infer schema automatically from query results and "),a("strong",[s._v("DO NOT")]),s._v(" support manual schema declaration")]),s._v(" "),a("li",[s._v("Do not support additional file "),a("code",[s._v("options")]),s._v(" -> To do this, we first create and register an external table (temp table) and use that as a create")])]),s._v(" "),a("p",[a("strong",[s._v("Generated Columns")])]),s._v(" "),a("p",[s._v("Special type of column whose values are automatically generated based on user-specified function of an existing column. Special implementation of "),a("code",[s._v("check constraint")])]),s._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("CREATE")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("OR")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("REPLACE")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("TABLE")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<>")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n    id STRING"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("date")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("DATE")]),s._v(" GENERATED ALWAYS "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("function")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("using")]),s._v(" existing "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("column")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])])]),a("p",[s._v("If the value given for a generated column, does not match what the generated column would calculate, there's an error")]),s._v(" "),a("p",[a("strong",[s._v("Table Constraints")])]),s._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("ALTER")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("TABLE")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<>")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("ADD")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("CONSTRAINT")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v("constraint_name"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v("similar "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("to")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("where")]),s._v(" clause here"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("DESCRIBE")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("EXTENDED")]),s._v(" sales "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("-- Shown here the constraints")]),s._v("\n")])])]),a("p",[a("strong",[s._v("Enrich Tables with Additional Options & Metadata")])]),s._v(" "),a("ul",[a("li",[a("code",[s._v("current_timestamp()")])]),s._v(" "),a("li",[a("code",[s._v("input_file_name()")])]),s._v(" "),a("li",[a("code",[s._v("COMMENT")])]),s._v(" "),a("li",[a("code",[s._v("LOCATION")])]),s._v(" "),a("li",[a("code",[s._v("PARTITIONED BY")]),s._v("\nAs best practice, you should default to non-partitioned tables for most use cases")])]),s._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("CREATE")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("OR")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("REPLACE")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("TABLE")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<>")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("COMMENT")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<>")]),s._v("\nLOCATION "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<>")]),s._v("\nPARTITIONED "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("BY")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<>")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("AS")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("SELECT")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("FROM")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<>")]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("DESCRIBE")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("EXTENDED")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<>")]),s._v("\n")])])]),a("p",[a("strong",[s._v("Cloning Delta Tables")])]),s._v(" "),a("ul",[a("li",[a("code",[s._v("Deep Clone")]),s._v(" -> Incremental changes, all data files are copied over")]),s._v(" "),a("li",[a("code",[s._v("Shallow Clone")]),s._v(" -> No data files are copied, only delta transaction logs")])]),s._v(" "),a("p",[a("strong",[s._v("Writing to Delta Talbes")])]),s._v(" "),a("ul",[a("li",[a("code",[s._v("INSERT OVERWRITE")]),s._v(" -> Overwrites the full table (still ACID compliant). Expects the same schema (unless options are used)")]),s._v(" "),a("li",[a("code",[s._v("INSERT INTO")]),s._v(" -> Appends new rows. No built in guarantees for avoiding duplicates")]),s._v(" "),a("li",[a("code",[s._v("MERGE INTO")]),s._v(" -> Updates. Rather than having 3 txns, there's only one to do.")]),s._v(" "),a("li",[a("code",[s._v("CTAS")]),s._v(" -> Overwrites the full table (still ACID compliant). Allows to redefine schema")]),s._v(" "),a("li",[a("code",[s._v("COPY INTO")]),s._v(" -> Loads incrementally it's idempotent. Expects consistent schema")])]),s._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("--MERGE INTO")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("MERGE")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("INTO")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<>")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("USING")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<>")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("ON")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<>")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("WHEN")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("MATCHED")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("THEN")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<>")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("WHEN")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("NOT")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("MATCHED")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("THEN")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<>")]),s._v("\n")])])]),a("p",[a("strong",[s._v("SQL UDFs")])]),s._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("CREATE")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("OR")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("REPLACE")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("FUNCTION")]),s._v(" name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<>")]),s._v(" STRING"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("RETURNS")]),s._v(" STRING\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("RETURN")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v("FUNC"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("DESCRIBE")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("FUNCTION")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("EXTENDED")]),s._v(" name\n")])])]),a("p",[s._v("SQL UDFs persist between execution environemnts, exist as objects in the metastore and are governed by the same Table ACLs as Databases, tables or views")])])}),[],!1,null,null,null);t.default=r.exports}}]);