(window.webpackJsonp=window.webpackJsonp||[]).push([[47],{404:function(t,a,n){"use strict";n.r(a);var s=n(42),e=Object(s.a)({},(function(){var t=this,a=t.$createElement,n=t._self._c||a;return n("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[n("h1",{attrs:{id:"azure-dp-100-module-9"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#azure-dp-100-module-9"}},[t._v("#")]),t._v(" Azure DP-100 Module 9")]),t._v(" "),n("h2",{attrs:{id:"model-interpretability"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#model-interpretability"}},[t._v("#")]),t._v(" Model Interpretability")]),t._v(" "),n("p",[t._v("Based on the "),n("code",[t._v("Interpret-Community")]),t._v(" package.")]),t._v(" "),n("h3",{attrs:{id:"global-and-local-feature-importance"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#global-and-local-feature-importance"}},[t._v("#")]),t._v(" Global and Local Feature Importance")]),t._v(" "),n("p",[n("code",[t._v("Global feature")]),t._v(" importance quantifies the relative importance of each feature in the test dataset as a whole.")]),t._v(" "),n("p",[n("code",[t._v("Local feature")]),t._v(" importance measures the influence of each feature value for a specific individual prediction.")]),t._v(" "),n("h3",{attrs:{id:"automl-learning-explanations"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#automl-learning-explanations"}},[t._v("#")]),t._v(" AutoML Learning Explanations")]),t._v(" "),n("p",[t._v("To generate model explanations when using automated machine learning, you must enable model explainability.")]),t._v(" "),n("p",[t._v("To generate explanations you can:")]),t._v(" "),n("ul",[n("li",[t._v("Select the Explain best model configuration setting in the user interface.")]),t._v(" "),n("li",[t._v("Specify the "),n("code",[t._v("model_explanaibility")]),t._v(" option in the "),n("code",[t._v("AutoMLConfig")]),t._v(" object in the SDK"),n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[t._v("automl_config "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" AutoMLConfig"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Automated ML Experiment'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# <other configuration settings here...>")]),t._v("\n                            model_explainability"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),t._v("\n                            "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])])]),t._v(" "),n("p",[t._v("To view the explanations you can:")]),t._v(" "),n("ul",[n("li",[t._v("Open the experiment run in Studio and go to the "),n("code",[t._v("explanations")]),t._v(" tab")]),t._v(" "),n("li",[t._v("Use the "),n("code",[t._v("RunDetails")]),t._v(" widget to view an automated run in Jupyter")]),t._v(" "),n("li",[t._v("Use the "),n("code",[t._v("ExplanationClient")]),t._v(" class in the SDK"),n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" azureml"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("contrib"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("interpret"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("explanation"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("explanation_client "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" ExplanationClient\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Get the best model (2nd item in outputs)")]),t._v("\nbest_run"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" fitted_model "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" automl_run"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_output"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Get the feature explanations")]),t._v("\nclient "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ExplanationClient"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_run"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("best_run"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nexplanation "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" client"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("download_model_explanation"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nfeature_importances "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" explanation"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_feature_importance_dict"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])])]),t._v(" "),n("p",[n("strong",[t._v("Note:")]),t._v(" When "),n("code",[t._v("featurization")]),t._v(" is enabled for automated machine learning, the explanation includes the importance of the engineered features.")]),t._v(" "),n("h2",{attrs:{id:"model-explainers"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#model-explainers"}},[t._v("#")]),t._v(" Model Explainers")]),t._v(" "),n("p",[t._v("AML SDK can be used to create explianers for local models, even if they were not trained using AML experiments. It can be done by using the "),n("code",[t._v("azureml-interpret")]),t._v(" package")]),t._v(" "),n("p",[t._v("Types of explainers:")]),t._v(" "),n("ul",[n("li",[n("code",[t._v("MimicExplainer")]),t._v(": creates a global surrogate model")]),t._v(" "),n("li",[n("code",[t._v("TabularExplainer")]),t._v(": acts as a wrapper around various SHAP explainer algorithms")]),t._v(" "),n("li",[n("code",[t._v("PFIExplainer")]),t._v(": "),n("strong",[t._v("P")]),t._v("ermutation "),n("strong",[t._v("F")]),t._v("eature "),n("strong",[t._v("I")]),t._v("mportance explainer that analyzes feature importance by shuffling feature values and measuring the impact on prediction performance")])]),t._v(" "),n("p",[t._v("Example for Mimic Explainer")]),t._v(" "),n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" interpret"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("blackbox "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" MimicExplainer\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" interpret"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("glassbox "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" DecisionTreeExplainableModel\n\nmim_explainer "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" MimicExplainer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("model"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("loan_model"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                               initialization_examples"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("X_test"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                               explainable_model "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" DecisionTreeExplainableModel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                               features"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'loan_amount'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'income'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'age'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'marital_status'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                               classes"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'reject'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'approve'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("h3",{attrs:{id:"adding-interpretability-to-training-experiments"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#adding-interpretability-to-training-experiments"}},[t._v("#")]),t._v(" Adding Interpretability to Training Experiments")]),t._v(" "),n("p",[t._v("Both packages are required "),n("code",[t._v("azureml-interpret")]),t._v(" and "),n("code",[t._v("azureml-contrib-interpret")])]),t._v(" "),n("p",[t._v("To include an explanation in the run details, the training script must use the ExplanationClient.upload_model_explanation method to upload the explanation created by an Explainer.")]),t._v(" "),n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Import Azure ML run library")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" azureml"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("core"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("run "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Run\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" azureml"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("contrib"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("interpret"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("explanation"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("explanation_client "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" ExplanationClient\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" interpret"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("blackbox "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" TabularExplainer\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# other imports as required")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Get the experiment run context")]),t._v("\nrun "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Run"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_context"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# code to train model goes here")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Get explanation")]),t._v("\nexplainer "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" TabularExplainer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("model"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" X_train"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" features"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("features"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" classes"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("labels"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nexplanation "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" explainer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("explain_global"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("X_test"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Get an Explanation Client and upload the explanation")]),t._v("\nexplain_client "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ExplanationClient"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_run"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("run"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nexplain_client"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("upload_model_explanation"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("explanation"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" comment"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Tabular Explanation'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Complete the run")]),t._v("\nrun"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("complete"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("h3",{attrs:{id:"adding-interpretability-to-inferencing"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#adding-interpretability-to-inferencing"}},[t._v("#")]),t._v(" Adding Interpretability to Inferencing")]),t._v(" "),n("p",[t._v("First create a scoring explainer and add it to the "),n("code",[t._v("run(raw_data)")]),t._v(" function")]),t._v(" "),n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" interpret"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ext"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("blackbox "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" TabularExplainer\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" azureml"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("interpret"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("scoring"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("scoring_explainer "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" KernelScoringExplainer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" save\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" azureml"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("core "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Model\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Get a registered model")]),t._v("\nloan_model "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" ws"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("models"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'loan_model'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\ntab_explainer "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" TabularExplainer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("model "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" loan_model"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                             initialization_examples"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("X_test"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                             features"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'loan_amount'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'income'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'age'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'marital_status'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                             classes"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'reject'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'approve'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Create and save a scoring explainer")]),t._v("\nscoring_explainer "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" KernelScoringExplainer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tab_explainer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" X_test"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nsave"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("scoring_explainer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" directory"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'explainer'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" exist_ok"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Register the explainer (like a model)")]),t._v("\nModel"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("register"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ws"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" model_name"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'loan_explainer'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'explainer/scoring_explainer.pkl'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" json\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" joblib\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" azureml"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("core"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("model "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Model\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Called when the service is loaded")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("init")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("global")]),t._v(" model"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" explainer\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# load the model")]),t._v("\n    model_path "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Model"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_model_path"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'loan_model'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    model "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" joblib"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("load"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("model_path"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# load the explainer")]),t._v("\n    explainer_path "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Model"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_model_path"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'loan_explainer'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    explainer "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" joblib"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("load"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("explainer_path"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Called when a request is received")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("run")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("raw_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Get the input data")]),t._v("\n    data "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" np"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("json"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("loads"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("raw_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'data'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Get a prediction from the model")]),t._v("\n    predictions "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" model"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("predict"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Get explanations")]),t._v("\n    importance_values "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" explainer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("explain"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Return the predictions and explanations as JSON")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"predictions"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("predictions"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tolist"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"importance"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("importance_values"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[t._v("service "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Model"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("deploy"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ws"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'loan-svc'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("model"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" explainer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" inf_config"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dep_config"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])])}),[],!1,null,null,null);a.default=e.exports}}]);