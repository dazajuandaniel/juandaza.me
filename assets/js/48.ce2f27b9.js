(window.webpackJsonp=window.webpackJsonp||[]).push([[48],{405:function(t,s,a){"use strict";a.r(s);var e=a(42),n=Object(e.a)({},(function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"azure-dp-100-day-1"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#azure-dp-100-day-1"}},[t._v("#")]),t._v(" Azure DP-100 Day 1")]),t._v(" "),a("h2",{attrs:{id:"azure-ml-studio-concepts"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#azure-ml-studio-concepts"}},[t._v("#")]),t._v(" Azure ML Studio Concepts")]),t._v(" "),a("h4",{attrs:{id:"compute-resources"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#compute-resources"}},[t._v("#")]),t._v(" Compute Resources")]),t._v(" "),a("p",[t._v("This is where you'll manage all the compute targets for your data science activities.")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[t._v("* Compute instances: Add a new server\n* Compute clusters: Add a new cluster\n* Interface clusters: This is where you can create and manage compute targets on which to deploy your trained models as web services for client applications to consume\n* Attached compute: This is where you could attach a virtual machine or Databricks cluster that exists outside of your workspace\n")])])]),a("h4",{attrs:{id:"datastores"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#datastores"}},[t._v("#")]),t._v(" Datastores")]),t._v(" "),a("p",[t._v("Azure ML workspace already includes two datastores based on the Azure Storage account that was created along with the workspace. These are used to store notebooks, configuration files, and data")]),t._v(" "),a("h4",{attrs:{id:"datasets"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#datasets"}},[t._v("#")]),t._v(" Datasets")]),t._v(" "),a("p",[t._v("Datasets represent specific data files or tables that you plan to work with in Azure ML. Datasets have handy options available to have a quick glance at exploring the data:")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[t._v("1. Details tab: Provides general metadata details\n2. Explore tab: Brief overview of data content, quick plots, etc\n3. Consume tab: Code details on how to use the data\n4. Models\n")])])]),a("h4",{attrs:{id:"azure-ml-sdk"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#azure-ml-sdk"}},[t._v("#")]),t._v(" Azure ML SDK")]),t._v(" "),a("p",[t._v("Provides libraries to interact programatically with Azure")]),t._v(" "),a("h4",{attrs:{id:"visual-studio-codespace"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#visual-studio-codespace"}},[t._v("#")]),t._v(" Visual Studio Codespace")]),t._v(" "),a("p",[t._v("A Visual Studio Codespace is a hosted instance of Visual Studio Code that you can use in a web browser. Visual Studio Code is a general code editing environment, with support for various programming languages through the installation of  "),a("em",[t._v("extensions")]),t._v(". To work with Python, you'll need the Microsoft Python extension, which was installed for you along with some commonly used Python packages when you created this environment from the  "),a("strong",[t._v("DP100")]),t._v("  repo.")]),t._v(" "),a("p",[t._v("If you plan to work with Azure Machine Learning in a Visual Studio codespace (or a local installation of Visual Studio Code), the Azure Machine Learning extension can help make it easier to work with resources in your workspace without needing to switch between your code development environment and the Azure Machine Learning studio web interface.")]),t._v(" "),a("h3",{attrs:{id:"azure-ml-designer"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#azure-ml-designer"}},[t._v("#")]),t._v(" Azure ML Designer")]),t._v(" "),a("p",[t._v("The  "),a("code",[t._v("Designer")]),t._v("  interface provides a drag & drop environment in which you can define a workflow, or  "),a("em",[t._v("pipeline")]),t._v("  of data ingestion, transformation, and model training modules to create a machine learning model. You can then publish this pipeline as a web service that client applications can use for  "),a("code",[t._v("inferencing")]),t._v("  (generating predictions from new data).")]),t._v(" "),a("h4",{attrs:{id:"pipeline"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#pipeline"}},[t._v("#")]),t._v(" Pipeline:")]),t._v(" "),a("p",[t._v("A dataflow for training a machine learning model. It includes all the steps required to process and train. Each step is independently executed.")]),t._v(" "),a("h4",{attrs:{id:"training-scoring-evaluating-models"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#training-scoring-evaluating-models"}},[t._v("#")]),t._v(" Training, Scoring & Evaluating Models")]),t._v(" "),a("p",[t._v("General steps:")]),t._v(" "),a("ol",[a("li",[t._v("Use an algorithm module to specify type of module")]),t._v(" "),a("li",[t._v("Train the model by fitting the data -> For supervised learning algorithms, you must use the "),a("strong",[t._v("Train Model")]),t._v(" module and specify the label to be predicted from the features in the training data. For unsupervised clustering, you must use the "),a("strong",[t._v("Train Clustering Model")]),t._v(" module.")]),t._v(" "),a("li",[t._v("Split the data into Train/Test using the relevant module")]),t._v(" "),a("li",[t._v("Evaluate the model")])]),t._v(" "),a("p",[a("strong",[t._v("Note:")])]),t._v(" "),a("ol",[a("li",[t._v("You could try some different classification algorithms and compare the results (you can connect the outputs of the "),a("strong",[t._v("Split Data")]),t._v(" module to multiple "),a("strong",[t._v("Train Model")]),t._v(" and "),a("strong",[t._v("Score Model")]),t._v(" modules, and you can connect a second scored model to the "),a("strong",[t._v("Evaluate Model")]),t._v(" module to see a side-by-side comparison)")]),t._v(" "),a("li",[t._v("You can't evaluate an unsupervised clustering model using the "),a("strong",[t._v("Evaluate Model")]),t._v(" module. To evaluate a clustering model, you can use the model to assign data to clusters and then use custom code to compare cluster separation based on the distance to cluster center values produced for each data point, or calculate and plot a "),a("code",[t._v("Principal Component Analysis")]),t._v(" (PCA) to show the separation of clusters based on two principal components.")])]),t._v(" "),a("h4",{attrs:{id:"code-modules"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#code-modules"}},[t._v("#")]),t._v(" Code Modules")]),t._v(" "),a("p",[t._v("There are multiple OOTB code modules, but custom modules are accepted, these include the following:")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[t._v("* Apply SQL Transformation: A SQL statement based on the SQLite implementation of the SQL language.\n\n* Execute Python Script: Use this module to run a custom Python function that processes one or two input dataframes, and returns one or two output dataframes.\n\n* Create Python Model: You can use this module to implement code for a custom model in place of the built-in algorithms provided in the designer. Your code must implement a class named  AzureMLModel  with init, train, and predict  methods.\n\n* Execute R Script: Use this module to run a custom R function that processes one or two input dataframes, and returns one or two output dataframes.\n")])])]),a("h4",{attrs:{id:"interface-pipeline"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#interface-pipeline"}},[t._v("#")]),t._v(" Interface Pipeline")]),t._v(" "),a("p",[t._v("Having trained a model using a  "),a("code",[t._v("training pipeline")]),t._v(", you can use it to create an  "),a("code",[t._v("inference pipeline")]),t._v("  for either real-time or batch prediction. It encapsulates the steps required to use it as a web service.")]),t._v(" "),a("p",[t._v("Once deployed, it can be consumed quite easily.")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" urllib"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("request\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" json\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" os\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" ssl\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("allowSelfSignedHttps")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("allowed"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# bypass the server certificate verification on client side")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" allowed "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("not")]),t._v(" os"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("environ"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'PYTHONHTTPSVERIFY'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("''")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("and")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("getattr")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ssl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'_create_unverified_context'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        ssl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_create_default_https_context "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ssl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("_create_unverified_context\n\nallowSelfSignedHttps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# this line is needed if you use self-signed certificate in your scoring service.")]),t._v("\n\ndata "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Inputs"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n          "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"input0"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n          "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n              "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'PatientID'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"1882185"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Pregnancies'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"9"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'PlasmaGlucose'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"104"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'DiastolicBloodPressure'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"51"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'TricepsThickness'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"7"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'SerumInsulin'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"24"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'BMI'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"27.36983156"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'DiabetesPedigree'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"1.35047"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                    "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Age'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"43"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n              "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n          "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"GlobalParameters"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\nbody "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("str")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("encode"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("json"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dumps"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nurl "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'http://10.0.0.1:80/api/v1/service/diabetes_predictor/score'")]),t._v("\napi_key "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'a1234567890x'")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Replace this with the API key for the web service")]),t._v("\nheaders "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Content-Type'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'application/json'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Authorization'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Bearer '")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" api_key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\nreq "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" urllib"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("request"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Request"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("url"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" body"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" headers"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("try")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    response "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" urllib"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("request"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("urlopen"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("req"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    result "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" response"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("result"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("except")]),t._v(" urllib"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("error"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("HTTPError "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" error"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"The request failed with status code: "')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("str")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("error"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("code"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("error"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("info"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("json"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("loads"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("error"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("decode"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"utf8"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'ignore'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("h3",{attrs:{id:"experiments"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#experiments"}},[t._v("#")]),t._v(" Experiments")]),t._v(" "),a("p",[t._v("In Azure Machine Learning, an "),a("code",[t._v("experiment")]),t._v("  is used to run a script or a pipeline, and usually generates outputs and records metrics. An experiment can be run multiple times, with different data, code, or settings; and Azure Machine Learning tracks each run, enabling you to view run history and compare results for each run.")]),t._v(" "),a("p",[t._v("The "),a("code",[t._v("run context")]),t._v(" is used to initialize and end the experiment run tracked by AzureML")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" azureml"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("core "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Experiment\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# create an experiment variable")]),t._v("\nexperiment "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Experiment"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("workspace "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ws"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" name "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"my-experiment"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# start the experiment")]),t._v("\nrun "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" experiment"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("start_logging"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# experiment code goes here")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# end the experiment")]),t._v("\nrun"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("complete"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[t._v("Experiments are most useful when they produce metrics and outputs that can be tracked across runs.")]),t._v(" "),a("p",[t._v("Every experiment generates log files that include the messages that would be written to the terminal during interactive execution. This enables you to use simple print statements to write messages to the log. However, if you want to record named metrics for comparison across runs, you can do so by using the "),a("strong",[t._v("Run")]),t._v(" object; which provides a range of logging functions specifically for this purpose.")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" azureml"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("core "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Experiment\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pandas "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" pd\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Create an Azure ML experiment in your workspace")]),t._v("\nexperiment "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Experiment"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("workspace "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ws"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" name "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'my-experiment'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Start logging data from the experiment")]),t._v("\nrun "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" experiment"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("start_logging"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# load the dataset and count the rows")]),t._v("\ndata "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pd"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("read_csv"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'data.csv'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nrow_count "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("len")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Log the row count")]),t._v("\nrun"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("log"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'observations'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" row_count"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Complete the experiment")]),t._v("\nrun"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("complete"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[t._v("You can view the metrics logged by an experiment run in Azure Machine Learning studio or by using the "),a("strong",[t._v("RunDetails")]),t._v(" widget in a notebook.")]),t._v(" "),a("p",[t._v("In addition to logging metrics, an experiment can generate output files. You can run an experiment inline using the "),a("strong",[t._v("start_logging")]),t._v(" method of the "),a("strong",[t._v("Experiment")]),t._v(" object, but it's more common to encapsulate the experiment logic in a script and run the script as an experiment. An experiment script is just a Python code file that contains the code you want to run in the experiment. To run a script as an experiment, you must define a "),a("code",[t._v("run configuration")]),t._v(" that defines the Python environment in which the script will be run, and a "),a("code",[t._v("script run configuration")]),t._v(" that associates the run environment with the script. These are implemented by using the "),a("strong",[t._v("RunConfiguration")]),t._v(" and "),a("strong",[t._v("ScriptRunConfig")]),t._v(" objects.")]),t._v(" "),a("h3",{attrs:{id:"estimators"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#estimators"}},[t._v("#")]),t._v(" Estimators")]),t._v(" "),a("p",[t._v("Azure Machine Learning provides a higher level abstraction called an "),a("strong",[t._v("Estimator")]),t._v(" that encapsulates a run configuration and a script configuration in a single object, and for which there are pre-defined, framework-specific variants that already include the package dependencies for common machine learning frameworks such as Scikit-Learn, PyTorch, and Tensorflow")]),t._v(" "),a("p",[t._v("You can use a generic  "),a("strong",[t._v("Estimator")]),t._v("  class to define a run configuration for a training script like this:")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" azureml"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("estimator "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Estimator\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" azureml"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("core "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Experiment\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Create an estimator")]),t._v("\nestimator "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Estimator"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("source_directory"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'experiment_folder'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                      entry_script"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'training_script.py'")]),t._v("\n                      compute_target"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'local'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                      conda_packages"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'scikit-learn'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n                      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Create and run an experiment")]),t._v("\nexperiment "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Experiment"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("workspace "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ws"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" name "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'training_experiment'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nrun "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" experiment"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("submit"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("config"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("estimator"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("h4",{attrs:{id:"using-script-parameters"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#using-script-parameters"}},[t._v("#")]),t._v(" Using Script Parameters")]),t._v(" "),a("p",[t._v("You can increase the flexibility of script-based experiments by using parameters to set variables in the script. To use parameters in a script, you must use a library such as "),a("strong",[t._v("argparse")]),t._v(" to read the arguments passed to the script and assign them to variables.")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Set regularization hyperparameter")]),t._v("\nparser "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" argparse"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ArgumentParser"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nparser"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add_argument"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'--reg_rate'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("type")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("float")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dest"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'reg'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" default"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.01")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nargs "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" parser"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parse_args"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nreg "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" args"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reg\n")])])]),a("h4",{attrs:{id:"retrieving-registering-a-trained-model"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#retrieving-registering-a-trained-model"}},[t._v("#")]),t._v(" Retrieving/Registering a Trained Model")]),t._v(" "),a("p",[t._v("After running an experiment that trains a model you can use a reference to the  "),a("strong",[t._v("Run")]),t._v("  object to retrieve its outputs, including the trained model.")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# "run" is a reference to a completed experiment run')]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# List the files generated by the experiment")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("file")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" run"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_file_names"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("file")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Download a named file")]),t._v("\nrun"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("download_file"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'outputs/model.pkl'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" output_file_path"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'model.pkl'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" azureml"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("core "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Model\n\nmodel "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("register"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("workspace"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("ws"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                       model_name"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'classification_model'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                       model_path"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'model.pkl'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# local path")]),t._v("\n                       description"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'A classification model'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                       tags"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'dept'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'sales'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                       model_framework"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("Model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Framework"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("SCIKITLEARN"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                       model_framework_version"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'0.20.3'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])])}),[],!1,null,null,null);s.default=n.exports}}]);